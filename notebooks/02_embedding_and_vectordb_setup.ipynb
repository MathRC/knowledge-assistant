{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d76a3de-e919-4adf-b74e-ef3cf946bef4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## **1. Introduction**\n",
    "\n",
    "Now that the text chunks are prepared and saved as JSON files, the next step is to vectorize and index the chunks for semantic search. This notebook handles the core of the retrieval pipeline: converting text into a machine-understandable format and storing it in a specialized database.\n",
    "\n",
    "The process involves three main steps:\n",
    "1.  **Load the Data**: We'll load the two sets of chunks (`fixed_chunks.json` and `section_chunks.json`) that we created in the previous notebook.\n",
    "2.  **Generate Embeddings**: We'll use a powerful sentence transformer model to convert the text content of each chunk into a numerical vector, also known as an embedding. These vectors capture the semantic meaning of the text.\n",
    "3.  **Populate the Vector Database**: Finally, we'll set up a Weaviate vector database and import our chunks, storing their text, metadata, and corresponding vector embeddings.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8ca378-7ad2-401c-922f-3e2ae04e7c2e",
   "metadata": {},
   "source": [
    "## **2. Setup and Configuration**\n",
    "\n",
    "### **2.1. Libraries**\n",
    "\n",
    "This notebook relies on a few key libraries to handle the embedding and database operations:\n",
    "* **`torch`**: Used to check for GPU availability, which can significantly speed up the embedding generation process.\n",
    "* **`sentence-transformers`**: A library that provides an easy way to use state-of-the-art embedding models.\n",
    "* **`tqdm`**: A simple utility for creating smart progress bars, which is helpful for monitoring long-running tasks like encoding hundreds of chunks.\n",
    "* **`weaviate-client`**: The official Python client for interacting with the Weaviate vector database. We'll use it to create our data schema and import the chunks.\n",
    "\n",
    "### **2.2. The Embedding Model**\n",
    "\n",
    "For generating embeddings, I chose **`BAAI/bge-large-en-v1.5`**. This is a top-performing, open-source model that consistently ranks high on the MTEB (Massive Text Embedding Benchmark) leaderboard for retrieval tasks. Using a powerful, open-source model allows for high-quality semantic search without relying on paid APIs.\n",
    "\n",
    "The initial cells handle all the necessary setup. After defining the file paths and model configurations, the script checks for an available GPU to accelerate the process and then loads the powerful `BGE` embedding model into memory, making it ready for use.\n",
    "\n",
    "Next, the script loads both sets of chunks—our baseline fixed-size chunks and the more advanced section-based ones—from the JSON files. Instead of creating two separate database collections, both sets are combined into a single list to be stored together. This single-collection approach is more efficient and simplifies the evaluation process. Each chunk's metadata contains a `method` property (`'fixed_size'` or `'section_based'`), which will allow us to easily filter and compare the performance of each chunking strategy in the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "686660b3-5f16-4f75-a827-4462a6fcf119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS AND CONFIGURATION ===\n",
    "import weaviate\n",
    "import json\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Paths to processed chunks\n",
    "FIXED_CHUNK_PATH = '../data/processed/fixed_chunks.json'\n",
    "SECTION_CHUNK_PATH = '../data/processed/section_chunks.json'\n",
    "\n",
    "# Model and collection configuration\n",
    "MODEL_NAME = 'BAAI/bge-large-en-v1.5'\n",
    "COLLECTION_NAME = 'StyleGuide'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f97aa46-692e-43d3-b88d-9f6971b975dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CUDA available. Using GPU: NVIDIA GeForce GTX 1050 Ti\n",
      "✅ Embedding model loaded\n"
     ]
    }
   ],
   "source": [
    "# === DEVICE SETUP AND MODEL LOADING ===\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(f'✅ CUDA available. Using GPU: {torch.cuda.get_device_name(0)}')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('⚠️ CUDA not available. Using CPU.')\n",
    "\n",
    "embedding_model = SentenceTransformer(MODEL_NAME, device=device)\n",
    "print('✅ Embedding model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72034125-780d-4d34-84fb-bfa9aeae6013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 361 fixed-size chunks and 593 section-based chunks\n"
     ]
    }
   ],
   "source": [
    "# === LOAD PROCESSED CHUNKS ===\n",
    "with open(FIXED_CHUNK_PATH, 'r', encoding='utf-8') as f:\n",
    "    fixed_chunks = json.load(f)\n",
    "\n",
    "with open(SECTION_CHUNK_PATH, 'r', encoding='utf-8') as f:\n",
    "    section_chunks = json.load(f)\n",
    "\n",
    "all_chunks = section_chunks + fixed_chunks\n",
    "print(f'Loaded {len(fixed_chunks)} fixed-size chunks and {len(section_chunks)} section-based chunks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a77938-38ad-4ec6-9987-db004c7ca988",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22aa2e7d-7c24-4876-934f-611cb50ba2cc",
   "metadata": {},
   "source": [
    "## **3. Generating the Embeddings**\n",
    "\n",
    "With the model loaded and all chunks prepared, the next step is to iterate through each one and use the model to convert its text into a vector embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acc17917-2646-4e6c-bfd8-8011b952a9cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5567d456c79a4e9ea52a770bd78a292b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding chunks:   0%|          | 0/954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 954 embeddings\n"
     ]
    }
   ],
   "source": [
    "# === GENERATE EMBEDDINGS ===\n",
    "embeddings = []\n",
    "for chunk in tqdm(all_chunks, desc='Encoding chunks'):\n",
    "    text = chunk['text']\n",
    "    embedding = embedding_model.encode(text)\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "print(f'Generated {len(embeddings)} embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b56b347-0c2a-4499-86e3-8fae1ae445e2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f206c4-f1de-49b5-b4f0-eaecd8400d84",
   "metadata": {},
   "source": [
    "## **4. Populating the Vector Database**\n",
    "\n",
    "Now that we generated the vector embeddings, the final step is to load them into Weaviate. This will make our chunks searchable and ready for the retrieval experiments in the next notebook.\n",
    "\n",
    "The process is handled in three main parts:\n",
    "1.  **Creating a Clean Collection**: To ensure a fresh start every time the script is run, the code first checks if a collection named `StyleGuide` already exists and deletes it. This is a common practice during development to avoid errors or duplicate data.\n",
    "2.  **Defining the Data Schema**: Before we can add data, we need to tell Weaviate what our data objects will look like. The code creates a new collection and defines a schema with properties for all the metadata we generated in the first notebook (`chunk_id`, `text`, `part`, `chapter`, `method`, etc.). It also configures the vector index to use **cosine distance**. This metric is well-suited for text embeddings because it measures similarity based on the **direction** of the vectors (capturing semantic meaning) rather than their magnitude, which can be influenced by factors like text length.\n",
    "3.  **Batch Importing the Data**: Finally, the script iterates through our chunks and their corresponding embeddings. It uses Weaviate's efficient **batch import** feature to load 100 items at a time, storing both the chunk's metadata and its vector in a single database entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0793f08c-a1f2-420d-8325-0ada7e84036c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Imported 954 chunks into Weaviate\n"
     ]
    }
   ],
   "source": [
    "# === WEAVIATE SETUP AND DATA IMPORT ===\n",
    "with weaviate.connect_to_local() as client:\n",
    "    # Remove existing collection to ensure clean data import\n",
    "    if client.collections.exists(COLLECTION_NAME):\n",
    "        client.collections.delete(COLLECTION_NAME)\n",
    "\n",
    "    # Define collection schema with document metadata structure\n",
    "    collection = client.collections.create(\n",
    "        name=COLLECTION_NAME,\n",
    "        properties=[\n",
    "            weaviate.classes.config.Property(name='chunk_id', data_type=weaviate.classes.config.DataType.TEXT),\n",
    "            weaviate.classes.config.Property(name='text', data_type=weaviate.classes.config.DataType.TEXT),\n",
    "            weaviate.classes.config.Property(name='part', data_type=weaviate.classes.config.DataType.TEXT),\n",
    "            weaviate.classes.config.Property(name='chapter', data_type=weaviate.classes.config.DataType.TEXT),\n",
    "            weaviate.classes.config.Property(name='section', data_type=weaviate.classes.config.DataType.TEXT),\n",
    "            weaviate.classes.config.Property(name='subsection', data_type=weaviate.classes.config.DataType.TEXT),\n",
    "            weaviate.classes.config.Property(name='page_number', data_type=weaviate.classes.config.DataType.TEXT),\n",
    "            weaviate.classes.config.Property(name='token_count', data_type=weaviate.classes.config.DataType.INT),\n",
    "            weaviate.classes.config.Property(name='method', data_type=weaviate.classes.config.DataType.TEXT),\n",
    "            weaviate.classes.config.Property(name='source_document', data_type=weaviate.classes.config.DataType.TEXT),\n",
    "            weaviate.classes.config.Property(name='is_split', data_type=weaviate.classes.config.DataType.BOOL),\n",
    "        ],\n",
    "        # Configure vector index for custom embeddings\n",
    "        vector_index_config=weaviate.classes.config.Configure.VectorIndex.hnsw(\n",
    "            distance_metric=weaviate.classes.config.VectorDistances.COSINE\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Batch import chunks with pre-computed embeddings\n",
    "    with collection.batch.fixed_size(100) as batch:\n",
    "        for chunk, embedding in zip(all_chunks, embeddings):\n",
    "            chunk_properties = {\n",
    "                'chunk_id': chunk.get('chunk_id'),\n",
    "                'text': chunk.get('text'),\n",
    "                'part': chunk.get('part', 'N/A'),\n",
    "                'chapter': chunk.get('chapter', 'N/A'),\n",
    "                'section': chunk.get('section', 'N/A'),\n",
    "                'subsection': chunk.get('subsection', 'N/A'),\n",
    "                'page_number': str(chunk.get('page_number', 'N/A')),\n",
    "                'token_count': chunk.get('token_count'),\n",
    "                'method': chunk.get('method'),\n",
    "                'source_document': chunk.get('source_document'),\n",
    "                'is_split': chunk.get('is_split', False),\n",
    "            }\n",
    "            batch.add_object(\n",
    "                properties=chunk_properties,\n",
    "                vector=embedding.tolist()\n",
    "            )\n",
    "\n",
    "    print(f'✅ Imported {len(all_chunks)} chunks into Weaviate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f41ddc-9591-48d4-aac8-4f940d5e1640",
   "metadata": {},
   "source": [
    "We have now transformed our raw text chunks into a searchable vector index, setting the stage for the evaluation phase."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
