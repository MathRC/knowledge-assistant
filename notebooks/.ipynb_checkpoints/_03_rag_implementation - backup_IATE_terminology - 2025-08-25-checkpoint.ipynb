{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a34405a-4ea4-4476-bea4-58ac92f7f69f",
   "metadata": {},
   "source": [
    "# 03 - RAG Implementation\n",
    "\n",
    "## Overview\n",
    "This notebook implements the complete RAG (Retrieval-Augmented Generation) system:\n",
    "- Connects to existing Weaviate vector database\n",
    "- Integrates with local Llama model via Ollama\n",
    "- Creates an intelligent translation assistant for terminology queries\n",
    "\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceab9157-433c-4bc4-934a-a6009609f1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import requests\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291aaaff-5557-4aa6-a38e-6fa343b34d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efeb53dd-990b-4e5c-87b1-7a4c4eea8966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee2208cc-43aa-406d-87c2-af89b592137e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 14475 term pairs\n"
     ]
    }
   ],
   "source": [
    "# Load the cleaned IATE data\n",
    "try:\n",
    "    iate_terminology = pd.read_csv('../data/processed/iate_terminology_clean.csv')\n",
    "    print(f\"Loaded {len(iate_terminology)} term pairs\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(\"CSV file not found. Did you run the cleaning step?\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Failed to load CSV: {e}\")\n",
    "\n",
    "if iate_terminology.empty:\n",
    "    raise ValueError(\"Loaded CSV is empty. Check data preprocessing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9588db-1582-4466-9845-cd170ba84d70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a4921d7-019f-4cce-b374-4190f3e26fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 742 unique domains\n",
      "Sample domains: ['ACP countries', 'AGRI-FOODSTUFFS', 'AGRICULTURE, FORESTRY AND FISHERIES', 'Africa', 'African organisation', 'American organisation', 'Arab world', 'Asia and Oceania', 'Asian organisation', 'Asia‚ÄìPacific economic cooperation']\n"
     ]
    }
   ],
   "source": [
    "# Extract all unique domains from IATE data\n",
    "def extract_domains(iate_data):\n",
    "    \"\"\"Extract and clean all domains from IATE terminology\"\"\"\n",
    "    domains = set()\n",
    "    \n",
    "    for field in iate_data['subject_field'].dropna():\n",
    "        if field:\n",
    "            # Split by semicolon and clean each domain\n",
    "            domain_list = [d.strip() for d in field.split(';') if d.strip()]\n",
    "            domains.update(domain_list)\n",
    "    \n",
    "    return sorted(list(domains))\n",
    "\n",
    "# Get available domains\n",
    "available_domains = extract_domains(iate_terminology)\n",
    "print(f\"Found {len(available_domains)} unique domains\")\n",
    "print(\"Sample domains:\", available_domains[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c13f7c-7bbf-4471-b967-b5cbb22d784a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7455a798-9efd-42ca-bb67-5333f32d2db1",
   "metadata": {},
   "source": [
    "## 1. Connect to Existing Infrastructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5798b4df-87df-4abd-949e-e8e5c3902810",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f3d4f8e-40dc-487a-a6e1-837990ccd108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Weaviate...\n",
      "‚úÖ Connected to Weaviate - 14475 terminology entries available\n",
      "Loading embedding model...\n",
      "‚úÖ Embedding model loaded\n"
     ]
    }
   ],
   "source": [
    "# Connect to Weaviate (our vector database from notebook 02)\n",
    "print(\"Connecting to Weaviate...\")\n",
    "client = weaviate.connect_to_local(skip_init_checks=True)\n",
    "\n",
    "# Get our terminology collection\n",
    "collection = client.collections.get(\"TerminologyEntry\")\n",
    "\n",
    "# Verify connection and data\n",
    "total_objects = collection.aggregate.over_all(total_count=True)\n",
    "print(f\"‚úÖ Connected to Weaviate - {total_objects.total_count} terminology entries available\")\n",
    "\n",
    "# Load the embedding model (same as notebook 02)\n",
    "print(\"Loading embedding model...\")\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "print(\"‚úÖ Embedding model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d8a26c-4bdf-4ad3-81ed-1d8f557fd6af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc4932a6-e5e4-4226-bd97-46fdd2bf8398",
   "metadata": {},
   "source": [
    "## 2. Ollama Connection and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444d85b6-2217-4d28-b0f2-9ca45b235a09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2159413d-4499-4b6b-b1b6-1eb013fc4bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ollama connected: Connected successfully!\n"
     ]
    }
   ],
   "source": [
    "def test_ollama_connection():\n",
    "    \"\"\"Test connection to local Ollama instance\"\"\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"http://localhost:11434/api/generate\",\n",
    "            json={\n",
    "                \"model\": \"llama3.2:3b\",\n",
    "                \"prompt\": \"Hello, respond with just 'Connected successfully!'\",\n",
    "                \"stream\": False\n",
    "            },\n",
    "            timeout=30\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(f\"‚úÖ Ollama connected: {result.get('response', '').strip()}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå Ollama connection failed: {response.status_code}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error connecting to Ollama: {e}\")\n",
    "        print(\"Make sure Ollama is running: 'ollama serve' in terminal\")\n",
    "        return False\n",
    "\n",
    "# Test the connection\n",
    "ollama_connected = test_ollama_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e27900-1eb2-401d-ac0b-1e1eccc804ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9990d5a-25af-4080-b5f7-eaabf578b1d2",
   "metadata": {},
   "source": [
    "## 3. Core RAG Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b240eb-8a79-4d2d-8e7b-de03d0cccfff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d609b37f-6ff1-46e7-8cf7-a26127ab35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_terminology(query, n_results=5):\n",
    "    \"\"\"\n",
    "    Search for relevant terminology using semantic similarity\n",
    "    \"\"\"\n",
    "    # Generate embedding for the query\n",
    "    query_embedding = model.encode([query])\n",
    "    \n",
    "    # Use REST API for reliable search\n",
    "    url = \"http://localhost:8080/v1/graphql\"\n",
    "    \n",
    "    graphql_query = {\n",
    "        \"query\": \"\"\"\n",
    "        {\n",
    "            Get {\n",
    "                TerminologyEntry(\n",
    "                    nearVector: {vector: %s}\n",
    "                    limit: %d\n",
    "                ) {\n",
    "                    pt_term\n",
    "                    en_term\n",
    "                    subject_field\n",
    "                    pt_reliability\n",
    "                    en_reliability\n",
    "                    _additional {\n",
    "                        distance\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \"\"\" % (json.dumps(query_embedding[0].tolist()), n_results)\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=graphql_query)\n",
    "        result = response.json()\n",
    "        \n",
    "        if 'data' in result and 'Get' in result['data']:\n",
    "            return result['data']['Get']['TerminologyEntry']\n",
    "        else:\n",
    "            print(f\"Search error: {result}\")\n",
    "            return []\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Search error: {e}\")\n",
    "        return []\n",
    "\n",
    "def query_llama(prompt, max_tokens=500):\n",
    "    \"\"\"\n",
    "    Send a prompt to Llama and get response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.post(\n",
    "            \"http://localhost:11434/api/generate\",\n",
    "            json={\n",
    "                \"model\": \"llama3.2:3b\",\n",
    "                \"prompt\": prompt,\n",
    "                \"stream\": False,\n",
    "                \"options\": {\n",
    "                    \"num_predict\": max_tokens,\n",
    "                    \"temperature\": 0.3\n",
    "                }\n",
    "            },\n",
    "            timeout=60\n",
    "        )\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            return result.get('response', '').strip()\n",
    "        else:\n",
    "            return f\"Error: {response.status_code}\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        return f\"Error querying Llama: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6503df1e-282b-43fe-bc83-57eaf31acf05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdfb188c-9bb2-4734-8ee6-1735b71526eb",
   "metadata": {},
   "source": [
    "## 4. RAG Pipeline Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8228be6e-00a7-4516-a388-1fb8d8b2824c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d48a9451-c1a8-4664-b744-f3682160ae16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing query: 'Como traduzir 'com√©rcio internacional'?'\n",
      "------------------------------------------------------------\n",
      "üîç Searching for relevant terminology...\n",
      "Found 5 relevant terms\n",
      "ü§ñ Generating response...\n",
      "Test Response:\n",
      "Ol√°!\n",
      "\n",
      "For 'com√©rcio internacional', I recommend considering the following translations:\n",
      "\n",
      "1. **Trade**: This is the most straightforward translation, as it directly conveys the meaning of \"com√©rcio internacional\".\n",
      "2. **International trade**: This option provides more context and clarity, especially when dealing with specific regulations or policies related to international commerce.\n",
      "3. **Foreign trade**: While this option is also acceptable, it may have a slightly different connotation, implying trade between countries.\n",
      "\n",
      "The reliability scores for the provided IATE entries suggest that all options are reliable, but 'trade' (option 1) has a higher similarity score with the Portuguese term \"com√©rcio internacional\" compared to the other options.\n",
      "\n",
      "When in doubt, consider the context and domain of your translation. If you're working on a document related to tariffs or regulations, option 2 ('International trade') might be more suitable. However, if you're dealing with general commerce or business-to-business transactions, 'trade' (option 1) could be a better choice.\n",
      "\n",
      "Boa sorte com sua tradu√ß√£o!\n"
     ]
    }
   ],
   "source": [
    "def create_context_from_results(search_results):\n",
    "    \"\"\"\n",
    "    Format search results into context for the LLM\n",
    "    \"\"\"\n",
    "    if not search_results:\n",
    "        return \"No relevant terminology found.\"\n",
    "    \n",
    "    context = \"Relevant terminology from IATE database:\\n\\n\"\n",
    "    \n",
    "    for i, result in enumerate(search_results, 1):\n",
    "        similarity = 1 - result['_additional']['distance']\n",
    "        context += f\"{i}. Portuguese: {result['pt_term']}\\n\"\n",
    "        context += f\"   English: {result['en_term']}\\n\"\n",
    "        context += f\"   Domain: {result['subject_field']}\\n\"\n",
    "        context += f\"   Similarity: {similarity:.3f}\\n\"\n",
    "        context += f\"   Reliability: PT={result['pt_reliability']}, EN={result['en_reliability']}\\n\\n\"\n",
    "    \n",
    "    return context\n",
    "\n",
    "def rag_query(user_question):\n",
    "    \"\"\"\n",
    "    Complete RAG pipeline: retrieve relevant terms and generate response\n",
    "    \"\"\"\n",
    "    print(f\"Processing query: '{user_question}'\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Step 1: Search for relevant terminology\n",
    "    print(\"üîç Searching for relevant terminology...\")\n",
    "    search_results = search_terminology(user_question, n_results=5)\n",
    "    \n",
    "    if not search_results:\n",
    "        return \"Sorry, I couldn't find relevant terminology for your query.\"\n",
    "    \n",
    "    print(f\"Found {len(search_results)} relevant terms\")\n",
    "    \n",
    "    # Step 2: Create context from search results\n",
    "    context = create_context_from_results(search_results)\n",
    "    \n",
    "    # Step 3: Create prompt for LLM\n",
    "    prompt = f\"\"\"You are a helpful translation assistant specializing in Portuguese-English terminology. \n",
    "A user has asked about translation terminology, and I've found relevant entries from the IATE (Inter-Agency Terminology Exchange) database.\n",
    "\n",
    "User Question: {user_question}\n",
    "\n",
    "{context}\n",
    "\n",
    "Please provide a helpful response that:\n",
    "1. Directly answers the user's question\n",
    "2. Explains the most relevant translation options\n",
    "3. Mentions the domain/context when relevant\n",
    "4. Notes reliability scores if they vary significantly\n",
    "5. Keep the response concise and practical for a translator\n",
    "\n",
    "Response:\"\"\"\n",
    "    \n",
    "    # Step 4: Query LLM\n",
    "    print(\"ü§ñ Generating response...\")\n",
    "    response = query_llama(prompt)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Test the RAG pipeline with a simple query\n",
    "if ollama_connected:\n",
    "    test_response = rag_query(\"Como traduzir 'com√©rcio internacional'?\")\n",
    "    print(\"Test Response:\")\n",
    "    print(test_response)\n",
    "else:\n",
    "    print(\"Skipping RAG test - Ollama not connected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2030ba1d-2b1f-4dae-9fe0-e6b7484edd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66328b64-061f-4578-85db-6edf58f5ab13",
   "metadata": {},
   "source": [
    "## 5. Enhanced Query Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6293b5-c6f0-40de-a4b2-9506b839ee21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6697356f-4400-4d22-88e5-b1c35f03622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translation_assistant(query, show_details=True):\n",
    "    \"\"\"\n",
    "    User-friendly interface for the translation assistant\n",
    "    \"\"\"\n",
    "    print(\"=\" * 80)\n",
    "    print(\"üåê TRANSLATION TERMINOLOGY ASSISTANT\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    if show_details:\n",
    "        print(f\"Query: {query}\")\n",
    "        print()\n",
    "    \n",
    "    # Get RAG response\n",
    "    response = rag_query(query)\n",
    "    \n",
    "    print(\"üí° RESPONSE:\")\n",
    "    print(response)\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Example usage function\n",
    "def run_example_queries():\n",
    "    \"\"\"\n",
    "    Demonstrate the system with various types of queries\n",
    "    \"\"\"\n",
    "    example_queries = [\n",
    "        \"Como traduzir 'produto agr√≠cola' para ingl√™s?\",\n",
    "        \"What is the English term for 'transporte mar√≠timo'?\",\n",
    "        \"Preciso da tradu√ß√£o de 'acordo comercial'\",\n",
    "        \"Como se diz 'com√©rcio internacional' em ingl√™s?\",\n",
    "        \"What are the translation options for 'denomina√ß√£o de origem'?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"üöÄ RUNNING EXAMPLE QUERIES\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for query in example_queries:\n",
    "        translation_assistant(query, show_details=False)\n",
    "        print(\"\\n\" + \"-\" * 40 + \"\\n\")\n",
    "\n",
    "# Run examples if Ollama is connected\n",
    "if ollama_connected:\n",
    "    print(\"Testing with example queries...\")\n",
    "    run_example_queries()\n",
    "else:\n",
    "    print(\"Connect Ollama to test example queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3d2f43-f0b6-4395-b074-72ed9033d050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83b9a7bd-b45b-4011-b7ec-0e458a86f6c6",
   "metadata": {},
   "source": [
    "## 6. Advanced Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d021dc-8981-4d20-aa10-7fe4244207c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99898929-12e2-4930-82a6-a775c398eaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_search(query, domain_filter=None, min_reliability=None, n_results=5):\n",
    "    \"\"\"\n",
    "    Search with additional filtering options\n",
    "    \"\"\"\n",
    "    # Base search (we'll enhance this with GraphQL filters)\n",
    "    results = search_terminology(query, n_results=n_results*2)  # Get more, then filter\n",
    "    \n",
    "    # Apply filters\n",
    "    filtered_results = []\n",
    "    \n",
    "    for result in results:\n",
    "        # Domain filter\n",
    "        if domain_filter and domain_filter.lower() not in result['subject_field'].lower():\n",
    "            continue\n",
    "            \n",
    "        # Reliability filter\n",
    "        if min_reliability:\n",
    "            try:\n",
    "                pt_rel = int(result['pt_reliability'])\n",
    "                en_rel = int(result['en_reliability'])\n",
    "                if pt_rel < min_reliability or en_rel < min_reliability:\n",
    "                    continue\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        filtered_results.append(result)\n",
    "        \n",
    "        if len(filtered_results) >= n_results:\n",
    "            break\n",
    "    \n",
    "    return filtered_results\n",
    "\n",
    "def expert_rag_query(user_question, domain_filter=None, min_reliability=None):\n",
    "    \"\"\"\n",
    "    RAG query with advanced filtering\n",
    "    \"\"\"\n",
    "    print(f\"Expert query: '{user_question}'\")\n",
    "    if domain_filter:\n",
    "        print(f\"Domain filter: {domain_filter}\")\n",
    "    if min_reliability:\n",
    "        print(f\"Minimum reliability: {min_reliability}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Enhanced search\n",
    "    search_results = filtered_search(\n",
    "        user_question, \n",
    "        domain_filter=domain_filter, \n",
    "        min_reliability=min_reliability\n",
    "    )\n",
    "    \n",
    "    if not search_results:\n",
    "        return \"No terminology found matching your criteria.\"\n",
    "    \n",
    "    # Create enhanced context\n",
    "    context = create_context_from_results(search_results)\n",
    "    \n",
    "    # Enhanced prompt\n",
    "    prompt = f\"\"\"You are an expert translation assistant. A user has asked about terminology with specific requirements.\n",
    "\n",
    "User Question: {user_question}\n",
    "{f\"Domain Focus: {domain_filter}\" if domain_filter else \"\"}\n",
    "{f\"Minimum Reliability: {min_reliability}\" if min_reliability else \"\"}\n",
    "\n",
    "{context}\n",
    "\n",
    "Provide a precise, expert-level response that addresses the specific requirements and explains why these terms are the best matches.\n",
    "\n",
    "Response:\"\"\"\n",
    "    \n",
    "    response = query_llama(prompt, max_tokens=600)\n",
    "    return response\n",
    "\n",
    "# Example of advanced usage\n",
    "def demonstrate_advanced_features():\n",
    "    \"\"\"\n",
    "    Show advanced filtering capabilities\n",
    "    \"\"\"\n",
    "    print(\"üéØ ADVANCED FEATURES DEMONSTRATION\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # High-reliability agricultural terms\n",
    "    print(\"1. High-reliability agricultural terms:\")\n",
    "    response = expert_rag_query(\n",
    "        \"produto agr√≠cola\", \n",
    "        domain_filter=\"agriculture\", \n",
    "        min_reliability=9\n",
    "    )\n",
    "    print(response)\n",
    "    print(\"\\n\" + \"-\" * 40 + \"\\n\")\n",
    "    \n",
    "    # Trade-specific terms\n",
    "    print(\"2. Trade-specific terms:\")\n",
    "    response = expert_rag_query(\n",
    "        \"acordo comercial\", \n",
    "        domain_filter=\"trade\"\n",
    "    )\n",
    "    print(response)\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "if ollama_connected:\n",
    "    demonstrate_advanced_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723e8a7a-5af2-407e-a3ba-6b54775f1f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c5788c3-b513-45a8-b839-a89051e60bfa",
   "metadata": {},
   "source": [
    "## 7. Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cadcf1-8e35-40ea-aeb8-28c2b6917d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7da8f6-02ae-472e-bd76-fd22576face2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_rag_performance():\n",
    "    \"\"\"\n",
    "    Analyze the performance of our RAG system\n",
    "    \"\"\"\n",
    "    print(\"üìä RAG SYSTEM PERFORMANCE ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Test queries with expected results\n",
    "    test_cases = [\n",
    "        (\"com√©rcio internacional\", [\"world trade\", \"international trade\"]),\n",
    "        (\"produto agr√≠cola\", [\"agricultural product\", \"basic agricultural product\"]),\n",
    "        (\"transporte mar√≠timo\", [\"shipping\", \"maritime transport\"]),\n",
    "        (\"acordo comercial\", [\"trade agreement\", \"trade deal\"])\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for query, expected_terms in test_cases:\n",
    "        print(f\"\\nTesting: '{query}'\")\n",
    "        \n",
    "        # Search for terms\n",
    "        search_results = search_terminology(query, n_results=3)\n",
    "        \n",
    "        if search_results:\n",
    "            found_terms = [result['en_term'].lower() for result in search_results]\n",
    "            \n",
    "            # Check if any expected terms are found\n",
    "            matches = []\n",
    "            for expected in expected_terms:\n",
    "                for found in found_terms:\n",
    "                    if expected.lower() in found or found in expected.lower():\n",
    "                        matches.append(expected)\n",
    "                        break\n",
    "            \n",
    "            accuracy = len(matches) / len(expected_terms)\n",
    "            avg_similarity = np.mean([1 - r['_additional']['distance'] for r in search_results])\n",
    "            \n",
    "            results.append({\n",
    "                'query': query,\n",
    "                'accuracy': accuracy,\n",
    "                'avg_similarity': avg_similarity,\n",
    "                'found_terms': found_terms[:3]\n",
    "            })\n",
    "            \n",
    "            print(f\"  Accuracy: {accuracy:.2%}\")\n",
    "            print(f\"  Avg Similarity: {avg_similarity:.3f}\")\n",
    "            print(f\"  Top results: {', '.join(found_terms[:3])}\")\n",
    "        else:\n",
    "            print(\"  No results found\")\n",
    "    \n",
    "    # Overall performance\n",
    "    if results:\n",
    "        overall_accuracy = np.mean([r['accuracy'] for r in results])\n",
    "        overall_similarity = np.mean([r['avg_similarity'] for r in results])\n",
    "        \n",
    "        print(f\"\\nüìà OVERALL PERFORMANCE:\")\n",
    "        print(f\"Average Accuracy: {overall_accuracy:.2%}\")\n",
    "        print(f\"Average Similarity: {overall_similarity:.3f}\")\n",
    "        print(f\"Total test cases: {len(results)}\")\n",
    "\n",
    "# Run performance analysis\n",
    "analyze_rag_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061f47cd-2abd-4889-8937-2bdc12bfe0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a16ecbce-09c1-4149-88e7-291f53b3eaed",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has successfully implemented a complete RAG system for translation terminology:\n",
    "\n",
    "‚úÖ **Completed Features:**\n",
    "- Vector database integration (Weaviate)\n",
    "- Local LLM integration (Llama 3.2:3b via Ollama)\n",
    "- Semantic search with Portuguese-English terminology\n",
    "- Intelligent response generation\n",
    "- Advanced filtering by domain and reliability\n",
    "- Performance evaluation\n",
    "\n",
    "‚úÖ **Key Capabilities:**\n",
    "- Natural language queries in Portuguese or English\n",
    "- Contextual translation suggestions\n",
    "- Domain-specific terminology lookup\n",
    "- Quality-filtered results based on IATE reliability scores\n",
    "- Production-ready architecture with local deployment\n",
    "\n",
    "‚úÖ **Ready for Production:**\n",
    "- Dockerized vector database\n",
    "- Local LLM deployment\n",
    "- RESTful API interfaces\n",
    "- Easily scalable to AWS/cloud platforms\n",
    "\n",
    "The system demonstrates enterprise-level RAG implementation suitable for translation agencies and language service providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2dd177-d883-465d-af97-c9f84e065bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5d447b-eed5-45a3-aadf-ff264ba69848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7b2cfe-1031-42c9-8af2-bfc1acafe6f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c125d4-4f84-448b-8cf4-4657f721344b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2270268f-c3aa-4bbb-80db-1189e80bcd0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f0e9c3-eeb0-4ae4-9596-c13b930b61df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04002a7-c795-44d2-890f-98b739bfe07c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
