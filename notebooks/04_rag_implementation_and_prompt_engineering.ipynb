{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c573a10-8761-4fc5-be38-78a9ba2a56dd",
   "metadata": {},
   "source": [
    "## **1. Introduction**\n",
    "\n",
    "This notebook builds the final **Retrieval-Augmented Generation (RAG)** pipeline, using the insights gained from our retrieval experiments in Notebook 03. It combines the optimized retriever (section-based chunks with hybrid search) with a large language model (LLM) to generate natural language answers based solely on the retrieved context from the European Commission's English Style Guide. We will also evaluate the impact of prompt engineering on reducing hallucinations.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0544239c-b4f1-4426-9eb3-d7e732136a70",
   "metadata": {},
   "source": [
    "## **2. Initializing the RAG System**\n",
    "\n",
    "The first step is to set up the environment by importing the necessary libraries and defining the core configurations for our RAG pipeline. \n",
    "\n",
    "### **2.1. Configuration Details**\n",
    "\n",
    "* **LLM Configuration**: This section specifies how we'll access the large language model (LLM) for the generation step.\n",
    "    * **Amazon Bedrock** was chosen as the LLM provider because it's a **fully managed service**. This simplifies deployment and scaling, eliminating the need to manage infrastructure. Bedrock also offers easy access to a **variety of foundation models** from different providers through a single API, making it flexible for future experimentation.\n",
    "    * The model selected was **Anthropic's Claude 3 Sonnet** (`CLAUDE_MODEL_ID`). Sonnet offers a great balance between **strong performance** (especially in reasoning and following instructions, which is essential for RAG) and **cost-effectiveness**. It has a large context window and is well-suited for tasks like summarizing retrieved information and generating accurate answers based on provided text.\n",
    "* **RAG Project Configuration**: This section defines the parameters specific to our RAG setup, namely the Weaviate collection name (`COLLECTION_NAME`), the embedding model used (`EMBEDDING_MODEL_NAME`), and the path for saving results (`RESULTS_FILE_PATH`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2fc946a-6fc3-4ba9-ae77-c5efcc3c9758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IMPORTS AND CONFIGURATION ===\n",
    "import weaviate\n",
    "import weaviate.classes.query as wq\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# --- LLM Configuration ---\n",
    "AWS_REGION = 'us-east-1'\n",
    "CLAUDE_MODEL_ID = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "\n",
    "# --- RAG Project Configuration ---\n",
    "COLLECTION_NAME = 'StyleGuide'\n",
    "EMBEDDING_MODEL_NAME = 'BAAI/bge-large-en-v1.5'\n",
    "RESULTS_FILE_PATH = '../results/rag_evaluation_results.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e33ab6-7223-47a9-a83d-31ab083d7b3a",
   "metadata": {},
   "source": [
    "### **2.2. Connecting to Bedrock and Weaviate**\n",
    "\n",
    "Next, we load the **BGE** embedding model into memory and connect to our two external services: **Weaviate** for retrieval and **Amazon Bedrock** for generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff800282-466d-433e-80ab-f1bf0ef8cab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing Models and Connecting to Services ---\n",
      "✅ Connected to Amazon Bedrock in region us-east-1\n",
      "✅ Connected to Weaviate collection 'StyleGuide'.\n"
     ]
    }
   ],
   "source": [
    "# === INITIALIZE MODELS AND CONNECTIONS ===\n",
    "print('--- Initializing Models and Connecting to Services ---')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME, device=device)\n",
    "\n",
    "bedrock_runtime = boto3.client(service_name='bedrock-runtime', region_name=AWS_REGION)\n",
    "print(f'✅ Connected to Amazon Bedrock in region {AWS_REGION}')\n",
    "\n",
    "client_weaviate = weaviate.connect_to_local()\n",
    "collection = client_weaviate.collections.get(COLLECTION_NAME)\n",
    "print(f'✅ Connected to Weaviate collection \\'{COLLECTION_NAME}\\'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cda616-baa3-46e6-9bcc-053b0bd473b5",
   "metadata": {},
   "source": [
    "### **2.3. Exponential Backoff for Bedrock Calls**\n",
    "\n",
    "When interacting with cloud-based LLMs like those on Amazon Bedrock, it's common to encounter temporary rate limits. To handle this efficiently, the function below implements an **exponential backoff mechanism**. If a request fails due to throttling (`ThrottlingException`), it automatically waits for a progressively longer period before retrying. This makes our pipeline more resilient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0836208-e122-4e74-b7f4-2b48206d1755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === BEDROCK INVOCATION WITH EXPONENTIAL BACKOFF ===\n",
    "def invoke_bedrock_with_backoff(body: str, model_id: str) -> dict:\n",
    "    \"\"\"\n",
    "    Invokes a Bedrock model with an exponential backoff retry mechanism.\n",
    "    Handles ThrottlingException errors by retrying the API call.\n",
    "    \"\"\"\n",
    "    max_retries = 5\n",
    "    base_delay = 2  # seconds\n",
    "    \n",
    "    for i in range(max_retries):\n",
    "        try:\n",
    "            response = bedrock_runtime.invoke_model(body=body, modelId=model_id)\n",
    "            return response\n",
    "        except ClientError as e:\n",
    "            if e.response['Error']['Code'] == 'ThrottlingException':\n",
    "                if i < max_retries - 1:\n",
    "                    delay = base_delay * (2 ** i)\n",
    "                    print(f'ThrottlingException caught. Retrying in {delay} seconds...')\n",
    "                    time.sleep(delay)\n",
    "                else:\n",
    "                    print('Max retries reached for ThrottlingException. Aborting.')\n",
    "                    raise e\n",
    "            else:\n",
    "                raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7563929-3cf6-49ff-ad62-d990870077e2",
   "metadata": {},
   "source": [
    "### **2.4. Defining the Retrieval Function**\n",
    "\n",
    "This function defines the **retriever component** of our RAG pipeline. Based on our findings in the previous notebook, it uses the optimized **hybrid search strategy (`alpha=0.7`)** on the **`section-based` chunks** in Weaviate. Given a user's question, it fetches the top 5 most relevant text chunks from the style guide to serve as context for the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fe23009-eef9-4d99-8b5e-14b30f745112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RETRIEVER FUNCTION ===\n",
    "def get_retrieved_context(question: str, limit: int = 5) -> str:\n",
    "    \"\"\"Retrieves context from Weaviate using the optimized hybrid search strategy.\"\"\"\n",
    "    question_vector = embedding_model.encode(question).tolist()\n",
    "    \n",
    "    response = collection.query.hybrid(\n",
    "        query=question,\n",
    "        vector=question_vector,\n",
    "        alpha=0.7,\n",
    "        limit=limit,\n",
    "        filters=wq.Filter.by_property('method').like('section_based*'),\n",
    "        return_properties=['text']\n",
    "    )\n",
    "    \n",
    "    if not response.objects:\n",
    "        return 'No relevant context was found in the style guide.'\n",
    "\n",
    "    context = \"\\n\\n---\\n\\n\".join([obj.properties['text'] for obj in response.objects])\n",
    "    return context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b8c9e1-2941-4092-b3ba-1d21a4911238",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4494a65-c7fa-4590-812b-d3464ebe33e0",
   "metadata": {},
   "source": [
    "## **3. Prompt Engineering for RAG**\n",
    "\n",
    "Although the retriever provides the relevant context, the quality of the final answer heavily depends on how we instruct the LLM to use that context. This section defines two distinct **prompt templates** to compare their effectiveness, particularly in reducing hallucinations and ensuring the LLM adheres strictly to the provided information.\n",
    "\n",
    "### **3.1. The Basic Prompt**\n",
    "\n",
    "The first template, `BASIC_PROMPT_TEMPLATE`, is a simple, direct instruction. It tells the LLM to answer the question based only on the provided context. This serves as our **baseline** to see how the LLM performs with minimal guidance.\n",
    "\n",
    "### **3.2. The Engineered Prompt**\n",
    "\n",
    "The second template, `ENGINEERED_PROMPT_TEMPLATE`, incorporates several **prompt engineering best practices** designed to improve accuracy and control the LLM's output for a RAG task:\n",
    "\n",
    "1.  **Role Definition:** It assigns a specific persona (\"You are a specialist assistant for the European Commission's English Style Guide\"), priming the model for the task.\n",
    "2.  **Strict Guidelines:** It provides explicit, numbered rules that constrain the LLM's behavior:\n",
    "      * Answer *only* from the context.\n",
    "      * Quote directly when possible.\n",
    "      * Provide a specific fallback response if the answer isn't in the context.\n",
    "      * Explicitly forbid the use of external knowledge.\n",
    "      * Demand precision about what the guide says versus doesn't say.\n",
    "3.  **Clear Structure:** It uses separators (`---`) to clearly delineate the context section from the question, making it easier for the model to parse the input.\n",
    "\n",
    "This engineered prompt aims to minimize the chances of the LLM hallucinating or deviating from the retrieved source material."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1080bb3-4c36-45be-a938-46c799af1f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === PROMPT TEMPLATES ===\n",
    "\n",
    "# A. Basic Prompt (Baseline)\n",
    "BASIC_PROMPT_TEMPLATE = '''\n",
    "Answer the following question based only on the provided context.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "'''\n",
    "\n",
    "# B. Engineered Prompt (Optimized)\n",
    "ENGINEERED_PROMPT_TEMPLATE = '''\n",
    "You are a specialist assistant for the European Commission's English Style Guide.\n",
    "\n",
    "STRICT GUIDELINES:\n",
    "1. Answer ONLY using information explicitly stated in the provided context.\n",
    "2. Quote directly from the context using quotation marks when possible.\n",
    "3. If the context lacks information to answer the question, respond: \"The European Commission's English Style Guide does not address this topic in the provided sections.\"\n",
    "4. Never use general knowledge about style guides, EU practices, or writing conventions.\n",
    "5. Be precise about what the guide says vs. what it doesn't say.\n",
    "\n",
    "Context from the Style Guide:\n",
    "---\n",
    "{context}\n",
    "---\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Response:\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29522270-2a2b-478e-9ece-c345576f528f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5d1a8c-a7e8-4f79-a516-5b90038c31fb",
   "metadata": {},
   "source": [
    "## **4. The RAG Pipeline Function**\n",
    "\n",
    "The next function, `get_rag_response`, brings all the components together to execute the complete RAG pipeline for a given question.\n",
    "\n",
    "It handles the process in several steps:\n",
    "\n",
    "1.  **Retrieve Context**: First, it calls the `get_retrieved_context` function (defined in Section 2.4) to fetch the relevant text chunks from Weaviate using our optimized hybrid search.\n",
    "2.  **Format Prompt**: It then takes the retrieved context and the user's question and inserts them into the chosen `prompt_template` (either the basic or engineered one).\n",
    "3.  **Prepare LLM Payload**: It constructs the JSON payload required by the Amazon Bedrock API for the Claude 3 Sonnet model. This includes the formatted prompt and an option to set the `temperature` parameter, which controls the creativity (randomness) of the LLM's response. We'll use this later to force more deterministic outputs for the engineered prompt.\n",
    "4.  **Invoke LLM**: It calls the `invoke_bedrock_with_backoff` function (defined in Section 2.3) to send the request to the LLM, automatically handling any potential throttling issues.\n",
    "5.  **Extract Answer**: Finally, it parses the JSON response from the LLM to extract the generated text answer.\n",
    "6.  **Return Results**: The function returns both the final answer and the context that was used to generate it, which is crucial for our later evaluation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "590fd177-0a3f-4303-b91a-92472b9753bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RAG PIPELINE FUNCTION ===\n",
    "def get_rag_response(question: str, prompt_template: str, temperature: float = None) -> dict:\n",
    "    \"\"\"\n",
    "    Generates an answer using a RAG pipeline and returns the answer and context.\n",
    "    Optionally sets the temperature for the LLM call to control creativity.\n",
    "    \"\"\"\n",
    "    context = get_retrieved_context(question)\n",
    "    final_prompt = prompt_template.format(context=context, question=question)\n",
    "    \n",
    "    payload = {\n",
    "        'anthropic_version': 'bedrock-2023-05-31',\n",
    "        'max_tokens': 1024,\n",
    "        'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': final_prompt}]}]\n",
    "    }\n",
    "    \n",
    "    if temperature is not None:\n",
    "        payload['temperature'] = temperature\n",
    "        \n",
    "    body = json.dumps(payload)\n",
    "    \n",
    "    response = invoke_bedrock_with_backoff(body=body, model_id=CLAUDE_MODEL_ID)\n",
    "    \n",
    "    response_body = json.loads(response.get('body').read())\n",
    "    answer = response_body.get('content')[0].get('text')\n",
    "    \n",
    "    return {'answer': answer, 'context': context}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57104cfa-0925-443f-8f72-0374d384c622",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ed0ea8-719e-427b-89ef-e8a95d5c22f0",
   "metadata": {},
   "source": [
    "## **5. The Hallucination Evaluation Framework**\n",
    "\n",
    "A good answer must be **grounded** in the source material and **free of hallucinations**. Since manually checking every answer isn't scalable, this section sets up an automated evaluation framework using another **LLM as a judge**.\n",
    "\n",
    "### **5.1. The Evaluator Prompt**\n",
    "\n",
    "The core of this framework is the **`EVALUATOR_PROMPT_TEMPLATE`**. This prompt instructs a second LLM (Claude 3 Sonnet again, but acting as a judge) to meticulously compare the generated answer against the source context provided to the RAG pipeline.\n",
    "\n",
    "Key instructions for the evaluator LLM include:\n",
    "\n",
    "  * Analyzing the answer **sentence by sentence**.\n",
    "  * Determining if each sentence is **fully supported** by the source context.\n",
    "  * Also considering a statement \"supported\" if it accurately claims that information is *not present* in the context.\n",
    "  * Outputting the analysis in a structured **JSON format**, including a sentence-level breakdown and a `final_verdict` (`SUPPORTED`, `PARTIALLY_SUPPORTED`, or `NOT_SUPPORTED`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52357ee-d8c2-44d1-8368-6004e24ce80c",
   "metadata": {},
   "source": [
    "### **5.2. The Evaluation Function**\n",
    "\n",
    "The **`evaluate_for_hallucination`** function handles this evaluation. It takes the original context and the generated answer, inserts them into the `EVALUATOR_PROMPT_TEMPLATE`, and sends this evaluation task to Bedrock (using the same robust backoff mechanism). It then parses the evaluator LLM's JSON response, providing a structured assessment of the answer's factual grounding.\n",
    "\n",
    "### **5.3. Calculating Metrics**\n",
    "\n",
    "Finally, the **`calculate_hallucination_metrics`** function takes the structured JSON results from multiple evaluations and calculates quantitative metrics, such as the overall accuracy rate (percentage of fully supported answers) and the hallucination rates (partial or complete). This allows us to easily compare the effectiveness of our basic vs. engineered prompts later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f098363-a718-4b48-b5d7-4131633b0ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HALLUCINATION EVALUATION FRAMEWORK ===\n",
    "\n",
    "EVALUATOR_PROMPT_TEMPLATE = '''\n",
    "You are a meticulous fact-checker. Your task is to evaluate a generated answer against a provided source context.\n",
    "\n",
    "Analyze the **Generated Answer** sentence by sentence. For each sentence, determine if the information is fully supported by the **Source Context**.\n",
    "A statement is \"supported\" if the source context contains information that directly proves it.\n",
    "**Crucially, a statement is ALSO considered \"supported\" if it accurately claims that information is NOT present in the context.**\n",
    "\n",
    "Your response MUST be in the following JSON format and nothing else:\n",
    "{{\n",
    "  \"analysis\": [\n",
    "    {{\n",
    "      \"sentence\": \"The first sentence of the generated answer.\",\n",
    "      \"is_supported\": boolean,\n",
    "      \"reasoning\": \"A brief explanation of why the sentence is or is not supported by the source context.\"\n",
    "    }}\n",
    "  ],\n",
    "  \"final_verdict\": \"SUPPORTED\", \"PARTIALLY_SUPPORTED\", or \"NOT_SUPPORTED\"\n",
    "}}\n",
    "\n",
    "---\n",
    "Source Context:\n",
    "{context}\n",
    "---\n",
    "Generated Answer:\n",
    "{answer}\n",
    "---\n",
    "'''\n",
    "\n",
    "def evaluate_for_hallucination(context: str, answer: str) -> dict:\n",
    "    \"\"\"Uses an LLM as a judge to evaluate if an answer is grounded in the provided context.\"\"\"\n",
    "    evaluator_prompt = EVALUATOR_PROMPT_TEMPLATE.format(context=context, answer=answer)\n",
    "    \n",
    "    body = json.dumps({\n",
    "        'anthropic_version': 'bedrock-2023-05-31',\n",
    "        'max_tokens': 2048,\n",
    "        'temperature': 0.0,\n",
    "        'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': evaluator_prompt}]}]\n",
    "    })\n",
    "    \n",
    "    try:\n",
    "        response = invoke_bedrock_with_backoff(body=body, model_id=CLAUDE_MODEL_ID)\n",
    "        response_body = json.loads(response.get('body').read())\n",
    "        evaluation_result_text = response_body.get('content')[0].get('text')\n",
    "        \n",
    "        # Extract the JSON object from the LLM's response, ignoring potential extra text.\n",
    "        json_match = re.search(r'\\{.*\\}', evaluation_result_text, re.DOTALL)\n",
    "        if json_match:\n",
    "            return json.loads(json_match.group(0))\n",
    "        else:\n",
    "            print(f'Error: No valid JSON object found in the evaluator\\'s response.')\n",
    "            return {'analysis': [], 'final_verdict': 'EVALUATION_FAILED'}\n",
    "            \n",
    "    except (json.JSONDecodeError, IndexError, Exception) as e:\n",
    "        print(f'Error parsing evaluation response: {e}')\n",
    "        return {'analysis': [], 'final_verdict': 'EVALUATION_FAILED'}\n",
    "\n",
    "def calculate_hallucination_metrics(evaluation_results: list) -> dict:\n",
    "    \"\"\"Calculates quantitative metrics from the structured evaluation results.\"\"\"\n",
    "    total_responses = len(evaluation_results)\n",
    "    if total_responses == 0: return {}\n",
    "        \n",
    "    supported = sum(1 for r in evaluation_results if r['final_verdict'] == 'SUPPORTED')\n",
    "    partial = sum(1 for r in evaluation_results if r['final_verdict'] == 'PARTIALLY_SUPPORTED')\n",
    "    not_supported = sum(1 for r in evaluation_results if r['final_verdict'] == 'NOT_SUPPORTED')\n",
    "\n",
    "    return {\n",
    "        'accuracy_rate': supported / total_responses,\n",
    "        'partial_hallucination_rate': partial / total_responses,\n",
    "        'hallucination_rate': not_supported / total_responses,\n",
    "        'total_evaluated': total_responses\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9dd77f-12a8-459b-b10f-d96203bf5fbc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fded26-4867-4374-b643-bbab60e3a5fa",
   "metadata": {},
   "source": [
    "## **6. Defining the Test Questions**\n",
    "\n",
    "Now we need a set of questions to evaluate our RAG pipeline. The **test set** that we'll use combines two types of questions:\n",
    "\n",
    "1.  **Factual Questions**: These are loaded directly from the `ground_truth.json` file we used in the previous notebook. We already know the correct answers for these, allowing us to evaluate basic retrieval and generation accuracy.\n",
    "2.  **Hallucination and Edge Case Questions**: These are new, carefully crafted questions designed to push the limits of the RAG system. They include:\n",
    "      * Questions about **topics not covered** in the style guide (e.g., \"Comic Sans font\"). This tests the system's ability to correctly state when information is missing, using the fallback response defined in the engineered prompt.\n",
    "      * Questions that ask for comparisons with **external knowledge** (e.g., \"Chicago Manual of Style\"), which the system should refuse based on the engineered prompt's rules.\n",
    "\n",
    "This combined set of questions provides a comprehensive test bed to evaluate both the accuracy and the robustness of our RAG pipeline, especially when comparing the basic and engineered prompts. The results for each question will be logged for later analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9a5c46e-ac90-48c9-bc49-884a4f792fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DEFINE TEST QUESTIONS ===\n",
    "\n",
    "# Load factual questions from the ground truth file.\n",
    "with open('../data/evaluation/ground_truth.json', 'r', encoding='utf-8') as f:\n",
    "    ground_truth_data = json.load(f)\n",
    "factual_questions = [q['question'] for q in ground_truth_data['questions']]\n",
    "\n",
    "# Define questions to test for hallucinations and edge cases.\n",
    "hallucination_and_edge_case_questions = [\n",
    "    'What is the official EU-approved font face and size for all official translated documents submitted in Microsoft Word format?',\n",
    "    'How do the EU\\'s rules on capitalizing government bodies differ from the Chicago Manual of Style?',\n",
    "    'What does the style guide say about using Comic Sans font?',\n",
    "    'How should translators handle Brexit-related terminology?',\n",
    "    'What are the differences between US and UK spelling in EU documents?',\n",
    "]\n",
    "\n",
    "test_questions = factual_questions + hallucination_and_edge_case_questions\n",
    "results_log = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f40874-d368-449f-8e99-05e05dd84ba2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3815ba05-7418-44fd-b742-ec96cc1069d1",
   "metadata": {},
   "source": [
    "## **7. Evaluation and Results**\n",
    "\n",
    "We're now ready to execute the RAG pipeline using both our basic and engineered prompts against the full set of test questions.\n",
    "\n",
    "The core experiment loop is executed in the cell below. For each question in our test suite:\n",
    "\n",
    "1.  It runs the **RAG pipeline** using the **basic prompt**.\n",
    "2.  It then uses our **LLM-based evaluator** to check the basic prompt's answer for factual grounding.\n",
    "3.  It repeats steps 1 and 2 using the **engineered prompt** (with `temperature=0.0` for deterministic output).\n",
    "4.  All results (answers, contexts, evaluations) are stored in the `results_log`.\n",
    "\n",
    "A 5-second pause is included between questions to respect API rate limits. The output below shows the detailed, question-by-question results, including the generated answers and the structured JSON evaluation from the LLM judge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eed690d5-aa63-43dd-a4ed-0fb9e19ba577",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running experiments on 10 questions ---\n",
      "\n",
      "====================== QUESTION 1/10 ======================\n",
      "QUESTION: When is it correct to use square brackets?\n",
      "----------------------------------------------------------\n",
      "\n",
      "--- 1. ANALYSIS OF BASIC PROMPT (Default Temperature) ---\n",
      "GENERATED ANSWER:\n",
      "According to the provided context, square brackets are used for the following purposes:\n",
      "\n",
      "1. To make editorial insertions or explanations in quoted material.\n",
      "Example: 'They [the members of the committee] voted in favour of the proposal.'\n",
      "\n",
      "2. In administrative drafting, to indicate optional passages or those still open to discussion.\n",
      "\n",
      "3. In mathematical formulae (but not in text), to enclose round brackets.\n",
      "Example: 7[4 ab – (2 nm × 6 bm ) × nm ] + 7 a = 1240\n",
      "\n",
      "4. When translating, to insert translations or explanations after names or titles left in the original language.\n",
      "\n",
      "5. To mark errors with '[sic]' or insert missing text when directly quoting a piece of text, as mentioned in section 1.2.\n",
      "\n",
      "So, in summary, square brackets are primarily used for editorial insertions, indicating optional text, enclosing brackets in mathematical formulae, providing translations/explanations when quoting, and marking errors or missing text in quoted material.\n",
      "\n",
      "--- Hallucination Evaluation ---\n",
      "{\n",
      "  \"analysis\": [\n",
      "    {\n",
      "      \"sentence\": \"According to the provided context, square brackets are used for the following purposes:\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"The source context introduces the uses of square brackets, so this sentence is supported.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"1. To make editorial insertions or explanations in quoted material. Example: 'They [the members of the committee] voted in favour of the proposal.'\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This use of square brackets is directly stated and exemplified in the source context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"2. In administrative drafting, to indicate optional passages or those still open to discussion.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This use of square brackets is directly stated in the source context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"3. In mathematical formulae (but not in text), to enclose round brackets. Example: 7[4 ab \\u2013 (2 nm \\u00d7 6 bm ) \\u00d7 nm ] + 7 a = 1240\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This use of square brackets is directly stated and exemplified in the source context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"4. When translating, to insert translations or explanations after names or titles left in the original language.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This use of square brackets is directly stated in the source context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"5. To mark errors with '[sic]' or insert missing text when directly quoting a piece of text, as mentioned in section 1.2.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This use of square brackets is directly stated in the source context under section 1.2.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"So, in summary, square brackets are primarily used for editorial insertions, indicating optional text, enclosing brackets in mathematical formulae, providing translations/explanations when quoting, and marking errors or missing text in quoted material.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This summary accurately captures the uses of square brackets stated in the source context.\"\n",
      "    }\n",
      "  ],\n",
      "  \"final_verdict\": \"SUPPORTED\"\n",
      "}\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- 2. ANALYSIS OF ENGINEERED PROMPT (Temperature = 0.0) ---\n",
      "GENERATED ANSWER:\n",
      "According to the European Commission's English Style Guide, square brackets should be used in the following cases:\n",
      "\n",
      "1. \"Square brackets are used to make editorial insertions in quoted material.\" For example: \"'They [the members of the committee] voted in favour of the proposal.'\"\n",
      "\n",
      "2. \"They may also be used in administrative drafting to indicate optional passages or those still open to discussion.\"\n",
      "\n",
      "3. \"In mathematical formulae (but not in text), square brackets are used to enclose round brackets.\"\n",
      "\n",
      "4. \"When translating, also use square brackets to insert translations or explanations after names or titles left in the original language.\"\n",
      "\n",
      "5. \"If necessary, you may mark errors with '[sic]' or insert missing text in square brackets\" when quoting text.\n",
      "\n",
      "The Style Guide does not provide any other explicit guidance on when to use square brackets.\n",
      "\n",
      "--- Hallucination Evaluation ---\n",
      "{\n",
      "  \"analysis\": [\n",
      "    {\n",
      "      \"sentence\": \"According to the European Commission's English Style Guide, square brackets should be used in the following cases:\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This introductory sentence sets up the context that the following points will be about the usage of square brackets according to the Style Guide.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"1. \\\"Square brackets are used to make editorial insertions in quoted material.\\\" For example: \\\"'They [the members of the committee] voted in favour of the proposal.'\\\"\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This point is directly supported by the first paragraph of the source context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"2. \\\"They may also be used in administrative drafting to indicate optional passages or those still open to discussion.\\\"\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This point is directly supported by the second sentence of the first paragraph of the source context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"3. \\\"In mathematical formulae (but not in text), square brackets are used to enclose round brackets.\\\"\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This point is directly supported by the third sentence of the first paragraph of the source context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"4. \\\"When translating, also use square brackets to insert translations or explanations after names or titles left in the original language.\\\"\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This point is directly supported by the last sentence of the first paragraph of the source context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"5. \\\"If necessary, you may mark errors with '[sic]' or insert missing text in square brackets\\\" when quoting text.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This point is directly supported by the last sentence of the source context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"The Style Guide does not provide any other explicit guidance on when to use square brackets.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This statement is supported because the source context does not mention any other cases for using square brackets.\"\n",
      "    }\n",
      "  ],\n",
      "  \"final_verdict\": \"SUPPORTED\"\n",
      "}\n",
      "\n",
      "Pausing for 5 seconds to avoid rate limiting...\n",
      "\n",
      "====================== QUESTION 2/10 ======================\n",
      "QUESTION: What’s the proper usage of an en dash?\n",
      "----------------------------------------------------------\n",
      "\n",
      "--- 1. ANALYSIS OF BASIC PROMPT (Default Temperature) ---\n",
      "GENERATED ANSWER:\n",
      "Based on the provided context, the proper usage of an en dash is:\n",
      "\n",
      "1. To signify a range of values, such as dates, numbers, or measurements (e.g., 10–12%, 2015–2019, 100 kW–40 MW).\n",
      "\n",
      "2. To separate a title from a subtitle when citing titles of publications or documents.\n",
      "\n",
      "3. As an alternative to commas or parentheses to set off a phrase or clause within a sentence, increasing contrast or emphasis. However, it should be used sparingly, with no more than one en dash or set of paired en dashes in a sentence.\n",
      "\n",
      "4. To join related or contrasting pairs.\n",
      "\n",
      "The context emphasizes using a closed-up en dash or hyphen for ranges, avoiding repetition of symbols or multiples when they don't change. It also mentions that en dashes can be used instead of commas or parentheses for inserted phrases, but advises against using them excessively, especially in legislation.\n",
      "\n",
      "--- Hallucination Evaluation ---\n",
      "{\n",
      "  \"analysis\": [\n",
      "    {\n",
      "      \"sentence\": \"Based on the provided context, the proper usage of an en dash is:\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is an introductory sentence setting up the subsequent points, which are supported by the context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"1. To signify a range of values, such as dates, numbers, or measurements (e.g., 10\\u201312%, 2015\\u20132019, 100 kW\\u201340 MW).\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This point is directly supported by the context, which states that en dashes or hyphens can be used to signify ranges (7.17, 3.31, 6.16).\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"2. To separate a title from a subtitle when citing titles of publications or documents.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This point is directly supported by the context, which states that en dashes may be used to separate the title from the subtitle when citing titles of publications or documents (2.17).\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"3. As an alternative to commas or parentheses to set off a phrase or clause within a sentence, increasing contrast or emphasis. However, it should be used sparingly, with no more than one en dash or set of paired en dashes in a sentence.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This point is directly supported by the context, which states that en dashes may be used instead of commas or parentheses to set off text and increase contrast or emphasis, but should be used sparingly with no more than one en dash or set of paired en dashes in a sentence (2.17).\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"4. To join related or contrasting pairs.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This point is directly supported by the context, which states that en dashes or hyphens may be used to join related or contrasting pairs (2.17).\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"The context emphasizes using a closed-up en dash or hyphen for ranges, avoiding repetition of symbols or multiples when they don't change.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This point is directly supported by the context, which states to use a closed-up en dash or hyphen for ranges and to avoid repeating symbols or multiples when they don't change (7.17, 6.16).\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"It also mentions that en dashes can be used instead of commas or parentheses for inserted phrases, but advises against using them excessively, especially in legislation.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This point is directly supported by the context, which states that en dashes may be used instead of commas or parentheses for inserted phrases, but advises against using them excessively, especially in legislation (2.17).\"\n",
      "    }\n",
      "  ],\n",
      "  \"final_verdict\": \"SUPPORTED\"\n",
      "}\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- 2. ANALYSIS OF ENGINEERED PROMPT (Temperature = 0.0) ---\n",
      "GENERATED ANSWER:\n",
      "According to the European Commission's English Style Guide, en dashes can be used for the following purposes:\n",
      "\n",
      "1. \"Short (or en) dashes may be used to punctuate a sentence instead of commas (see 2.13) or round brackets (see 2.19). They increase the contrast or emphasis of the text thus set off.\"\n",
      "\n",
      "2. \"When citing titles of publications or documents, use a short dash to separate the title from the subtitle (see also 4.11 on titles of publications).\"\n",
      "\n",
      "3. \"Either en dashes or hyphens may be used to join related or contrasting pairs (see 3.29) or to replace 'to' in a range (see 3.30).\"\n",
      "\n",
      "4. \"Ranges. Either en dashes or hyphens can be used to replace 'to' in a range, e.g. 2015–2019 (see also 6.21 on time spans).\"\n",
      "\n",
      "The guide provides specific guidance on using en dashes for ranges, contrasting pairs, separating titles and subtitles, and adding emphasis within sentences instead of commas or parentheses.\n",
      "\n",
      "--- Hallucination Evaluation ---\n",
      "{\n",
      "  \"analysis\": [\n",
      "    {\n",
      "      \"sentence\": \"According to the European Commission's English Style Guide, en dashes can be used for the following purposes:\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"The source context mentions that the information is from the European Commission's English Style Guide, and lists several uses of en dashes.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"1. \\\"Short (or en) dashes may be used to punctuate a sentence instead of commas (see 2.13) or round brackets (see 2.19). They increase the contrast or emphasis of the text thus set off.\\\"\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is a direct quote from the source context (section 2.17).\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"2. \\\"When citing titles of publications or documents, use a short dash to separate the title from the subtitle (see also 4.11 on titles of publications).\\\"\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is a direct quote from the source context (section 2.17).\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"3. \\\"Either en dashes or hyphens may be used to join related or contrasting pairs (see 3.29) or to replace 'to' in a range (see 3.30).\\\"\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is a direct quote from the source context (section 2.17).\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"4. \\\"Ranges. Either en dashes or hyphens can be used to replace 'to' in a range, e.g. 2015\\u20132019 (see also 6.21 on time spans).\\\"\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is a direct quote from the source context (section 3.31).\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"The guide provides specific guidance on using en dashes for ranges, contrasting pairs, separating titles and subtitles, and adding emphasis within sentences instead of commas or parentheses.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This summarizes the information provided in the previous sentences, which are all supported by the source context.\"\n",
      "    }\n",
      "  ],\n",
      "  \"final_verdict\": \"SUPPORTED\"\n",
      "}\n",
      "\n",
      "Pausing for 5 seconds to avoid rate limiting...\n",
      "\n",
      "====================== QUESTION 3/10 ======================\n",
      "QUESTION: Which spelling is correct: Rhein or Rhin?\n",
      "----------------------------------------------------------\n",
      "\n",
      "--- 1. ANALYSIS OF BASIC PROMPT (Default Temperature) ---\n",
      "GENERATED ANSWER:\n",
      "According to the provided context in section 5.22, the correct spelling is Rhine for Rhein, Rhin, and Rijn.\n",
      "\n",
      "The context states: \"Write Rhine for Rhein, Rhin, and Rijn, and Rhineland for Rheinland.\"\n",
      "\n",
      "Therefore, the correct spelling to use is Rhine, not Rhein or Rhin.\n",
      "\n",
      "--- Hallucination Evaluation ---\n",
      "{\n",
      "  \"analysis\": [\n",
      "    {\n",
      "      \"sentence\": \"According to the provided context in section 5.22, the correct spelling is Rhine for Rhein, Rhin, and Rijn.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"The source context in section 5.22 directly states: \\\"Write Rhine for Rhein, Rhin, and Rijn, and Rhineland for Rheinland.\\\"\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"The context states: \\\"Write Rhine for Rhein, Rhin, and Rijn, and Rhineland for Rheinland.\\\"\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This sentence directly quotes the relevant part of the source context from section 5.22.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"Therefore, the correct spelling to use is Rhine, not Rhein or Rhin.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This conclusion accurately summarizes the information provided in the quoted context from section 5.22.\"\n",
      "    }\n",
      "  ],\n",
      "  \"final_verdict\": \"SUPPORTED\"\n",
      "}\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- 2. ANALYSIS OF ENGINEERED PROMPT (Temperature = 0.0) ---\n",
      "GENERATED ANSWER:\n",
      "According to the European Commission's English Style Guide, the correct spelling is \"Rhine\" for the river known as \"Rhein\" in German and \"Rhin\" in French. The guide states:\n",
      "\n",
      "\"Write Rhine for Rhein, Rhin, and Rijn, and Rhineland for Rheinland.\"\n",
      "\n",
      "So the spellings \"Rhein\" and \"Rhin\" are not recommended, and \"Rhine\" should be used instead.\n",
      "\n",
      "--- Hallucination Evaluation ---\n",
      "{\n",
      "  \"analysis\": [\n",
      "    {\n",
      "      \"sentence\": \"According to the European Commission's English Style Guide, the correct spelling is \\\"Rhine\\\" for the river known as \\\"Rhein\\\" in German and \\\"Rhin\\\" in French.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This sentence is supported by the source context, which states: \\\"Write Rhine for Rhein, Rhin, and Rijn, and Rhineland for Rheinland.\\\"\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"The guide states: \\\"Write Rhine for Rhein, Rhin, and Rijn, and Rhineland for Rheinland.\\\"\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is a direct quote from the source context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"So the spellings \\\"Rhein\\\" and \\\"Rhin\\\" are not recommended, and \\\"Rhine\\\" should be used instead.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is a correct inference from the quote in the source context, which states to use \\\"Rhine\\\" instead of \\\"Rhein\\\", \\\"Rhin\\\", and \\\"Rijn\\\".\"\n",
      "    }\n",
      "  ],\n",
      "  \"final_verdict\": \"SUPPORTED\"\n",
      "}\n",
      "\n",
      "Pausing for 5 seconds to avoid rate limiting...\n",
      "\n",
      "====================== QUESTION 4/10 ======================\n",
      "QUESTION: Is it better to use the symbol '*' or 'x' for multiplication?\n",
      "----------------------------------------------------------\n",
      "\n",
      "--- 1. ANALYSIS OF BASIC PROMPT (Default Temperature) ---\n",
      "GENERATED ANSWER:\n",
      "Based on the provided context, it is better to use the multiplication sign (×) instead of an 'x' or '*' for multiplication. Specifically, section 7.15 states:\n",
      "\n",
      "\"Change a point or a raised dot used as a multiplication sign to × or *, e.g. 2.6 · 10^18 becomes 2.6 × 10^18 or 2.6 * 10^18.\"\n",
      "\n",
      "While it allows the use of either × or *, it recommends replacing an 'x' with the dedicated multiplication sign ×.\n",
      "\n",
      "Additionally, section 7.13 reinforces this by stating \"do not use a letter 'x' as a multiplication sign, as these can make equations inaccessible to people using screen readers.\"\n",
      "\n",
      "Therefore, according to the provided context, it is better and more accessible to use the multiplication symbol × rather than 'x' or '*' when representing multiplication in mathematical equations.\n",
      "\n",
      "--- Hallucination Evaluation ---\n",
      "{\n",
      "  \"analysis\": [\n",
      "    {\n",
      "      \"sentence\": \"Based on the provided context, it is better to use the multiplication sign (\\u00d7) instead of an 'x' or '*' for multiplication.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is supported by section 7.15, which states \\\"Change a point or a raised dot used as a multiplication sign to \\u00d7 or *, e.g. 2.6 \\u00b7 10^18 becomes 2.6 \\u00d7 10^18 or 2.6 * 10^18.\\\"\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"Specifically, section 7.15 states: \\\"Change a point or a raised dot used as a multiplication sign to \\u00d7 or *, e.g. 2.6 \\u00b7 10^18 becomes 2.6 \\u00d7 10^18 or 2.6 * 10^18.\\\"\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is a direct quote from section 7.15.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"While it allows the use of either \\u00d7 or *, it recommends replacing an 'x' with the dedicated multiplication sign \\u00d7.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is a reasonable inference from the quote in section 7.15, which suggests replacing other symbols like a point or raised dot with \\u00d7 or *.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"Additionally, section 7.13 reinforces this by stating \\\"do not use a letter 'x' as a multiplication sign, as these can make equations inaccessible to people using screen readers.\\\"\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is a direct quote from section 7.13.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"Therefore, according to the provided context, it is better and more accessible to use the multiplication symbol \\u00d7 rather than 'x' or '*' when representing multiplication in mathematical equations.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is a reasonable conclusion based on the information provided in sections 7.13 and 7.15, which recommend using the dedicated multiplication symbol \\u00d7 over other symbols like 'x' or '*' for accessibility reasons.\"\n",
      "    }\n",
      "  ],\n",
      "  \"final_verdict\": \"SUPPORTED\"\n",
      "}\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- 2. ANALYSIS OF ENGINEERED PROMPT (Temperature = 0.0) ---\n",
      "GENERATED ANSWER:\n",
      "According to the European Commission's English Style Guide, it is better to use the multiplication sign '×' rather than 'x' or '*' for multiplication. The guide states:\n",
      "\n",
      "\"Change a point or a raised dot used as a multiplication sign to × or *, e.g. 2.6 · 10^18 becomes 2.6 × 10^18 or 2.6 * 10^18.\"\n",
      "\n",
      "While it allows the use of either '×' or '*', it specifically recommends changing 'x' to '×' when used as a multiplication sign. The guide does not provide a preference between '×' and '*'.\n",
      "\n",
      "--- Hallucination Evaluation ---\n",
      "{\n",
      "  \"analysis\": [\n",
      "    {\n",
      "      \"sentence\": \"According to the European Commission's English Style Guide, it is better to use the multiplication sign '\\u00d7' rather than 'x' or '*' for multiplication.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"The source context states: \\\"Change a point or a raised dot used as a multiplication sign to \\u00d7 or *, e.g. 2.6 \\u00b7 10^18 becomes 2.6 \\u00d7 10^18 or 2.6 * 10^18.\\\" This directly supports the statement that '\\u00d7' should be used instead of 'x' or a raised dot for multiplication.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"The guide states: \\\"Change a point or a raised dot used as a multiplication sign to \\u00d7 or *, e.g. 2.6 \\u00b7 10^18 becomes 2.6 \\u00d7 10^18 or 2.6 * 10^18.\\\"\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is a direct quote from the source context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"While it allows the use of either '\\u00d7' or '*', it specifically recommends changing 'x' to '\\u00d7' when used as a multiplication sign.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"The source context states to change 'x' to '\\u00d7' or '*' when used as a multiplication sign, which supports the claim that it specifically recommends changing 'x' to '\\u00d7'.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"The guide does not provide a preference between '\\u00d7' and '*'.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"The source context does not state a preference between '\\u00d7' and '*', so the claim that it does not provide a preference is supported.\"\n",
      "    }\n",
      "  ],\n",
      "  \"final_verdict\": \"SUPPORTED\"\n",
      "}\n",
      "\n",
      "Pausing for 5 seconds to avoid rate limiting...\n",
      "\n",
      "====================== QUESTION 5/10 ======================\n",
      "QUESTION: Is there a space before or after suspension points?\n",
      "----------------------------------------------------------\n",
      "\n",
      "--- 1. ANALYSIS OF BASIC PROMPT (Default Temperature) ---\n",
      "GENERATED ANSWER:\n",
      "According to the provided context, there are specific rules regarding the use of spaces before and after ellipsis points (suspension points):\n",
      "\n",
      "1. When placed at the beginning of the text, the ellipsis is followed by a normal space.\n",
      "\n",
      "2. When replacing one or more words in the middle of a sentence, the ellipsis is preceded by a hard space and followed by a normal space.\n",
      "\n",
      "3. When replacing one or more words at the end of a sentence, the ellipsis is preceded by a hard space.\n",
      "\n",
      "So in summary, there is no space before an ellipsis when it replaces words in the middle or end of a sentence, but it is preceded by a hard space in those cases. When the ellipsis is at the beginning of text, it is followed by a normal space.\n",
      "\n",
      "--- Hallucination Evaluation ---\n",
      "{\n",
      "  \"analysis\": [\n",
      "    {\n",
      "      \"sentence\": \"According to the provided context, there are specific rules regarding the use of spaces before and after ellipsis points (suspension points):\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"The source context provides rules for the use of ellipses, including when spaces should be used before and after them.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"1. When placed at the beginning of the text, the ellipsis is followed by a normal space.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is directly stated in the source context: \\\"When placed at the beginning of the text, it is followed by a normal space.\\\"\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"2. When replacing one or more words in the middle of a sentence, the ellipsis is preceded by a hard space and followed by a normal space.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is directly stated in the source context: \\\"When replacing one or more words in the middle of a sentence, it is preceded by a hard space 2 and followed by a normal space.\\\"\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"3. When replacing one or more words at the end of a sentence, the ellipsis is preceded by a hard space.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is directly stated in the source context: \\\"When replacing one or more words at the end of a sentence, it is preceded by a hard space 2 .\\\"\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"So in summary, there is no space before an ellipsis when it replaces words in the middle or end of a sentence, but it is preceded by a hard space in those cases. When the ellipsis is at the beginning of text, it is followed by a normal space.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This summary accurately reflects the rules stated in the previous sentences, which are all supported by the source context.\"\n",
      "    }\n",
      "  ],\n",
      "  \"final_verdict\": \"SUPPORTED\"\n",
      "}\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- 2. ANALYSIS OF ENGINEERED PROMPT (Temperature = 0.0) ---\n",
      "GENERATED ANSWER:\n",
      "According to the European Commission's English Style Guide, there are specific guidelines for using spaces with ellipses (suspension points):\n",
      "\n",
      "\"When placed at the beginning of the text, it [an ellipsis] is followed by a normal space.\"\n",
      "\n",
      "\"When replacing one or more words in the middle of a sentence, it is preceded by a hard space and followed by a normal space.\"\n",
      "\n",
      "\"When replacing one or more words at the end of a sentence, it is preceded by a hard space.\"\n",
      "\n",
      "So there is a normal space after an ellipsis at the beginning of text, and a hard space before but a normal space after an ellipsis replacing words in the middle or end of a sentence.\n",
      "\n",
      "--- Hallucination Evaluation ---\n",
      "{\n",
      "  \"analysis\": [\n",
      "    {\n",
      "      \"sentence\": \"According to the European Commission's English Style Guide, there are specific guidelines for using spaces with ellipses (suspension points):\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"The source context mentions guidelines for using ellipses, so this introductory sentence is supported.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"\\\"When placed at the beginning of the text, it [an ellipsis] is followed by a normal space.\\\"\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is a direct quote from the source context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"\\\"When replacing one or more words in the middle of a sentence, it is preceded by a hard space and followed by a normal space.\\\"\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is also a direct quote from the source context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"\\\"When replacing one or more words at the end of a sentence, it is preceded by a hard space.\\\"\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is another direct quote from the source context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"So there is a normal space after an ellipsis at the beginning of text, and a hard space before but a normal space after an ellipsis replacing words in the middle or end of a sentence.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This summarizes the information from the previous quotes, which are directly supported by the source context.\"\n",
      "    }\n",
      "  ],\n",
      "  \"final_verdict\": \"SUPPORTED\"\n",
      "}\n",
      "\n",
      "Pausing for 5 seconds to avoid rate limiting...\n",
      "\n",
      "====================== QUESTION 6/10 ======================\n",
      "QUESTION: What is the official EU-approved font face and size for all official translated documents submitted in Microsoft Word format?\n",
      "----------------------------------------------------------\n",
      "\n",
      "--- 1. ANALYSIS OF BASIC PROMPT (Default Temperature) ---\n",
      "GENERATED ANSWER:\n",
      "Unfortunately, there is no information provided in the given context about the official EU-approved font face and size for translated documents submitted in Microsoft Word format. The context discusses writing style guidelines, the Official Journal, official/working languages within the EU institutions, but does not mention specifics about formatting requirements for translated document submissions.\n",
      "\n",
      "--- Hallucination Evaluation ---\n",
      "{\n",
      "  \"analysis\": [\n",
      "    {\n",
      "      \"sentence\": \"Unfortunately, there is no information provided in the given context about the official EU-approved font face and size for translated documents submitted in Microsoft Word format.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"The source context does not mention anything about font face and size requirements for translated documents submitted in Word format, so this sentence accurately claims that such information is not present.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"The context discusses writing style guidelines, the Official Journal, official/working languages within the EU institutions, but does not mention specifics about formatting requirements for translated document submissions.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"The source context covers topics like writing style guidelines, the Official Journal, and official/working languages, but does not provide details on formatting requirements for translated document submissions, so this sentence is supported.\"\n",
      "    }\n",
      "  ],\n",
      "  \"final_verdict\": \"SUPPORTED\"\n",
      "}\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- 2. ANALYSIS OF ENGINEERED PROMPT (Temperature = 0.0) ---\n",
      "GENERATED ANSWER:\n",
      "The European Commission's English Style Guide does not address this topic in the provided sections.\n",
      "\n",
      "ThrottlingException caught. Retrying in 2 seconds...\n",
      "--- Hallucination Evaluation ---\n",
      "{\n",
      "  \"analysis\": [\n",
      "    {\n",
      "      \"sentence\": \"The European Commission's English Style Guide does not address this topic in the provided sections.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"The provided source context does not contain any information about the European Commission's English Style Guide addressing the topic mentioned in the generated answer. Therefore, the statement that the Style Guide does not address this topic in the provided sections is accurate and supported.\"\n",
      "    }\n",
      "  ],\n",
      "  \"final_verdict\": \"SUPPORTED\"\n",
      "}\n",
      "\n",
      "Pausing for 5 seconds to avoid rate limiting...\n",
      "\n",
      "====================== QUESTION 7/10 ======================\n",
      "QUESTION: How do the EU's rules on capitalizing government bodies differ from the Chicago Manual of Style?\n",
      "----------------------------------------------------------\n",
      "\n",
      "--- 1. ANALYSIS OF BASIC PROMPT (Default Temperature) ---\n",
      "GENERATED ANSWER:\n",
      "Based on the context provided, the EU style guide differs from the Chicago Manual of Style in how it capitalizes government bodies and titles in the following ways:\n",
      "\n",
      "1. It capitalizes all nouns and adjectives when writing out the full titles of organizations, institutions, directorates, units, sections, office holders, committees, delegations, etc. For example: \"Publications and Dissemination Directorate\", \"Business Development and Support Unit\".\n",
      "\n",
      "2. For long descriptive names that read more like a description than a formal title, it recommends capitalizing only the head word and using lowercase for the rest. For example: \"Committee for the adaptation to technical progress of the Directive on the introduction of recording equipment in road transport\".\n",
      "\n",
      "3. When using shortened forms or referring back to the names of strategies, programs, action plans etc., it recommends using lowercase, even if the shortened form is not much shorter than the original title.\n",
      "\n",
      "4. It makes exceptions and uses capitals for references to permanent EU bodies/formations like \"College of Commissioners\", \"Directorates-General\" and official functions like \"Members of the Commission\", even in the plural form.\n",
      "\n",
      "The Chicago Manual of Style has some different capitalization rules, but the EU style guide does not explicitly compare or contrast its approach with other major style guides in the context provided. The focus is on establishing clear internal conventions for capitalizing various EU governmental bodies, programs and titles.\n",
      "\n",
      "--- Hallucination Evaluation ---\n",
      "{\n",
      "  \"analysis\": [\n",
      "    {\n",
      "      \"sentence\": \"Based on the context provided, the EU style guide differs from the Chicago Manual of Style in how it capitalizes government bodies and titles in the following ways:\",\n",
      "      \"is_supported\": false,\n",
      "      \"reasoning\": \"The source context does not mention or compare the EU style guide's capitalization rules to the Chicago Manual of Style.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"1. It capitalizes all nouns and adjectives when writing out the full titles of organizations, institutions, directorates, units, sections, office holders, committees, delegations, etc. For example: \\\"Publications and Dissemination Directorate\\\", \\\"Business Development and Support Unit\\\".\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is directly stated in the source under section 4.5.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"2. For long descriptive names that read more like a description than a formal title, it recommends capitalizing only the head word and using lowercase for the rest. For example: \\\"Committee for the adaptation to technical progress of the Directive on the introduction of recording equipment in road transport\\\".\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is also directly stated with the same example in section 4.5.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"3. When using shortened forms or referring back to the names of strategies, programs, action plans etc., it recommends using lowercase, even if the shortened form is not much shorter than the original title.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is stated in section 4.7 about using lowercase for short forms.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"4. It makes exceptions and uses capitals for references to permanent EU bodies/formations like \\\"College of Commissioners\\\", \\\"Directorates-General\\\" and official functions like \\\"Members of the Commission\\\", even in the plural form.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This exception is mentioned in section 4.7.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"The Chicago Manual of Style has some different capitalization rules, but the EU style guide does not explicitly compare or contrast its approach with other major style guides in the context provided.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"The context does not mention or compare the EU style guide's capitalization rules to other style guides like the Chicago Manual of Style, so this statement accurately claims that such a comparison is not present.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"The focus is on establishing clear internal conventions for capitalizing various EU governmental bodies, programs and titles.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is a reasonable summary of the focus described in the context.\"\n",
      "    }\n",
      "  ],\n",
      "  \"final_verdict\": \"PARTIALLY_SUPPORTED\"\n",
      "}\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- 2. ANALYSIS OF ENGINEERED PROMPT (Temperature = 0.0) ---\n",
      "GENERATED ANSWER:\n",
      "The European Commission's English Style Guide does not address how its rules on capitalizing government bodies differ from the Chicago Manual of Style or other external style guides. The guide provides its own internal rules and conventions for EU publications and documents, but does not make comparisons to other style guides used outside the EU institutions.\n",
      "\n",
      "--- Hallucination Evaluation ---\n",
      "{\n",
      "  \"analysis\": [\n",
      "    {\n",
      "      \"sentence\": \"The European Commission's English Style Guide does not address how its rules on capitalizing government bodies differ from the Chicago Manual of Style or other external style guides.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"The source context does not mention or compare the European Commission's capitalization rules to other style guides like the Chicago Manual of Style. So this sentence accurately states that such a comparison is not present in the context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"The guide provides its own internal rules and conventions for EU publications and documents, but does not make comparisons to other style guides used outside the EU institutions.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"The context states that the guide aims to provide rules and conventions for English usage within the EU institutions, without mentioning comparisons to external style guides. So this sentence is supported.\"\n",
      "    }\n",
      "  ],\n",
      "  \"final_verdict\": \"SUPPORTED\"\n",
      "}\n",
      "\n",
      "Pausing for 5 seconds to avoid rate limiting...\n",
      "\n",
      "====================== QUESTION 8/10 ======================\n",
      "QUESTION: What does the style guide say about using Comic Sans font?\n",
      "----------------------------------------------------------\n",
      "\n",
      "--- 1. ANALYSIS OF BASIC PROMPT (Default Temperature) ---\n",
      "GENERATED ANSWER:\n",
      "The provided context does not mention anything about using the Comic Sans font. The text covers topics like the purpose of the style guide, using clear language, handling quotes and formatting titles, and referring to other style guides for specific topics like postal code conventions. But there are no guidelines given regarding the use of the Comic Sans font specifically.\n",
      "\n",
      "--- Hallucination Evaluation ---\n",
      "{\n",
      "  \"analysis\": [\n",
      "    {\n",
      "      \"sentence\": \"The provided context does not mention anything about using the Comic Sans font.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"The source context does not contain any information about using the Comic Sans font, so this statement accurately claims that such information is not present.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"The text covers topics like the purpose of the style guide, using clear language, handling quotes and formatting titles, and referring to other style guides for specific topics like postal code conventions.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"The source context discusses these topics, so this summary is supported.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"But there are no guidelines given regarding the use of the Comic Sans font specifically.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This sentence reinforces the accurate claim that the source context does not mention guidelines about using the Comic Sans font.\"\n",
      "    }\n",
      "  ],\n",
      "  \"final_verdict\": \"SUPPORTED\"\n",
      "}\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- 2. ANALYSIS OF ENGINEERED PROMPT (Temperature = 0.0) ---\n",
      "GENERATED ANSWER:\n",
      "The European Commission's English Style Guide does not address this topic in the provided sections.\n",
      "\n",
      "--- Hallucination Evaluation ---\n",
      "{\n",
      "  \"analysis\": [\n",
      "    {\n",
      "      \"sentence\": \"The European Commission's English Style Guide does not address this topic in the provided sections.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"The provided source context does not contain any information about postal-code conventions, so the statement that the topic is not addressed in the given sections is accurate and supported.\"\n",
      "    }\n",
      "  ],\n",
      "  \"final_verdict\": \"SUPPORTED\"\n",
      "}\n",
      "\n",
      "Pausing for 5 seconds to avoid rate limiting...\n",
      "\n",
      "====================== QUESTION 9/10 ======================\n",
      "QUESTION: How should translators handle Brexit-related terminology?\n",
      "----------------------------------------------------------\n",
      "\n",
      "--- 1. ANALYSIS OF BASIC PROMPT (Default Temperature) ---\n",
      "GENERATED ANSWER:\n",
      "According to the context provided, when referring to events and developments related to the UK's withdrawal from the European Union, translators should take care to distinguish between \"Brexit\" itself and the \"Brexit referendum\" that took place on June 23, 2016. The guide states:\n",
      "\n",
      "\"Take care to distinguish between Brexit itself and the Brexit referendum. Some people have taken to referring to events following the Brexit referendum on 23 June 2016 as 'since Brexit' or 'in the post-Brexit world', when what they mean is 'since the Brexit referendum'. This is not only inaccurate, it is also loaded with political connotations. The UK did not actually leave the EU until 31 January 2020.\"\n",
      "\n",
      "So translators should be precise in their terminology - \"Brexit\" should refer specifically to the UK's withdrawal from the EU on January 31, 2020, while events between the 2016 referendum and the actual withdrawal should be described as occurring \"since the Brexit referendum\" or similar phrasing, rather than just saying \"since Brexit.\" The guide advises against the inaccurate and politically loaded use of \"Brexit\" to refer to the entire post-referendum period before the UK's actual exit.\n",
      "\n",
      "--- Hallucination Evaluation ---\n",
      "{\n",
      "  \"analysis\": [\n",
      "    {\n",
      "      \"sentence\": \"According to the context provided, when referring to events and developments related to the UK's withdrawal from the European Union, translators should take care to distinguish between \\\"Brexit\\\" itself and the \\\"Brexit referendum\\\" that took place on June 23, 2016.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This sentence accurately summarizes the key point made in the source context about distinguishing between 'Brexit' and the 'Brexit referendum'.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"The guide states:\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is just an introductory phrase to the quote from the source context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"\\\"Take care to distinguish between Brexit itself and the Brexit referendum. Some people have taken to referring to events following the Brexit referendum on 23 June 2016 as 'since Brexit' or 'in the post-Brexit world', when what they mean is 'since the Brexit referendum'. This is not only inaccurate, it is also loaded with political connotations. The UK did not actually leave the EU until 31 January 2020.\\\"\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is a direct quote from the source context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"So translators should be precise in their terminology - \\\"Brexit\\\" should refer specifically to the UK's withdrawal from the EU on January 31, 2020, while events between the 2016 referendum and the actual withdrawal should be described as occurring \\\"since the Brexit referendum\\\" or similar phrasing, rather than just saying \\\"since Brexit.\\\"\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This sentence accurately summarizes the guidance from the source context on how to use the terms 'Brexit' and 'Brexit referendum' precisely.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"The guide advises against the inaccurate and politically loaded use of \\\"Brexit\\\" to refer to the entire post-referendum period before the UK's actual exit.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This sentence accurately captures the source context's statement that using 'Brexit' to refer to the post-referendum period is 'inaccurate' and 'loaded with political connotations'.\"\n",
      "    }\n",
      "  ],\n",
      "  \"final_verdict\": \"SUPPORTED\"\n",
      "}\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- 2. ANALYSIS OF ENGINEERED PROMPT (Temperature = 0.0) ---\n",
      "GENERATED ANSWER:\n",
      "According to the provided context from the European Commission's English Style Guide, it states:\n",
      "\n",
      "\"Take care to distinguish between Brexit itself and the Brexit referendum. Some people have taken to referring to events following the Brexit referendum on 23 June 2016 as 'since Brexit' or 'in the post-Brexit world', when what they mean is 'since the Brexit referendum'. This is not only inaccurate, it is also loaded with political connotations. The UK did not actually leave the EU until 31 January 2020.\"\n",
      "\n",
      "Therefore, the Style Guide advises against using phrases like \"since Brexit\" or \"post-Brexit world\" to refer to the period after the 2016 referendum, as this is inaccurate. The UK did not actually leave the EU until January 31, 2020. The guide recommends carefully distinguishing between the Brexit referendum itself and the UK's eventual exit from the EU.\n",
      "\n",
      "--- Hallucination Evaluation ---\n",
      "{\n",
      "  \"analysis\": [\n",
      "    {\n",
      "      \"sentence\": \"According to the provided context from the European Commission's English Style Guide, it states:\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"The source context is an excerpt from the European Commission's English Style Guide.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"\\\"Take care to distinguish between Brexit itself and the Brexit referendum. Some people have taken to referring to events following the Brexit referendum on 23 June 2016 as 'since Brexit' or 'in the post-Brexit world', when what they mean is 'since the Brexit referendum'. This is not only inaccurate, it is also loaded with political connotations. The UK did not actually leave the EU until 31 January 2020.\\\"\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is a direct quote from the provided source context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"Therefore, the Style Guide advises against using phrases like \\\"since Brexit\\\" or \\\"post-Brexit world\\\" to refer to the period after the 2016 referendum, as this is inaccurate.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This accurately summarizes the advice given in the quoted text from the source context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"The UK did not actually leave the EU until January 31, 2020.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is directly stated in the quoted text from the source context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"The guide recommends carefully distinguishing between the Brexit referendum itself and the UK's eventual exit from the EU.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This accurately summarizes the advice given in the quoted text from the source context.\"\n",
      "    }\n",
      "  ],\n",
      "  \"final_verdict\": \"SUPPORTED\"\n",
      "}\n",
      "\n",
      "Pausing for 5 seconds to avoid rate limiting...\n",
      "\n",
      "====================== QUESTION 10/10 ======================\n",
      "QUESTION: What are the differences between US and UK spelling in EU documents?\n",
      "----------------------------------------------------------\n",
      "\n",
      "--- 1. ANALYSIS OF BASIC PROMPT (Default Temperature) ---\n",
      "GENERATED ANSWER:\n",
      "Based on the provided context, the key differences between US and UK spelling conventions for EU documents are:\n",
      "\n",
      "1. The -is-/-iz- spellings: EU texts should use the -is- spelling (e.g. realise, organise) rather than the US -iz- spelling (realize, organize). Both are considered correct, but -is- is preferred for consistency.\n",
      "\n",
      "2. Digraphs: Words like aetiology, caesium, oenology, oestrogen should retain the digraph (ae, oe) following British spelling, whereas the US spellings drop the digraph (etiology, cesium, enology, estrogen). However, some words like medieval and fetus are now commonly spelled without the digraph in British English as well.\n",
      "\n",
      "3. General preference: The guide states that for reasons of stylistic consistency, the variety of English followed is the \"shared standard usage of Ireland and the United Kingdom\", i.e. British/Irish spellings are preferred over American spellings in EU texts, with some exceptions allowed for words that have become standard usage (e.g. program, disk in IT contexts).\n",
      "\n",
      "4. Use of spellcheckers: Authors/translators are advised to use a spellchecker set to UK English as an aid, while also checking against dictionaries like the Oxford ones in case of doubt, with preference given to the primary British spelling listed.\n",
      "\n",
      "--- Hallucination Evaluation ---\n",
      "{\n",
      "  \"analysis\": [\n",
      "    {\n",
      "      \"sentence\": \"Based on the provided context, the key differences between US and UK spelling conventions for EU documents are:\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"The introduction states that the guide aims to provide instructions and advice based on the 'shared standard usage of Ireland and the United Kingdom', implying differences from US spelling conventions.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"1. The -is-/-iz- spellings: EU texts should use the -is- spelling (e.g. realise, organise) rather than the US -iz- spelling (realize, organize). Both are considered correct, but -is- is preferred for consistency.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is directly stated in the first paragraph under '3.2. -is-/-iz- spelling'.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"2. Digraphs: Words like aetiology, caesium, oenology, oestrogen should retain the digraph (ae, oe) following British spelling, whereas the US spellings drop the digraph (etiology, cesium, enology, estrogen). However, some words like medieval and fetus are now commonly spelled without the digraph in British English as well.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This information is provided in the paragraph under '3.6. Digraphs'.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"3. General preference: The guide states that for reasons of stylistic consistency, the variety of English followed is the \\\"shared standard usage of Ireland and the United Kingdom\\\", i.e. British/Irish spellings are preferred over American spellings in EU texts, with some exceptions allowed for words that have become standard usage (e.g. program, disk in IT contexts).\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is directly stated in the introduction paragraph.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"4. Use of spellcheckers: Authors/translators are advised to use a spellchecker set to UK English as an aid, while also checking against dictionaries like the Oxford ones in case of doubt, with preference given to the primary British spelling listed.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is mentioned in the second paragraph under '3.1. Irish/British spelling'.\"\n",
      "    }\n",
      "  ],\n",
      "  \"final_verdict\": \"SUPPORTED\"\n",
      "}\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "--- 2. ANALYSIS OF ENGINEERED PROMPT (Temperature = 0.0) ---\n",
      "GENERATED ANSWER:\n",
      "According to the provided sections from the European Commission's English Style Guide:\n",
      "\n",
      "1. The guide states to \"Use the -is- spelling\" for words like \"organis-e\" rather than the \"-iz-\" spelling like \"organiz-e\". It says \"Both spellings are correct, but this rule is to be followed for the sake of consistency in EU texts.\" (Section 3.2)\n",
      "\n",
      "2. For other spelling differences between US and UK English, it instructs to \"Follow standard Irish/British usage\" and use a spellchecker set to UK English. It recommends following \"the first spelling given on the Oxford Dictionaries Premium website\" for British English spellings. (Section 3.1)\n",
      "\n",
      "3. Regarding digraphs like \"ae\" and \"oe\", it states to \"Keep the digraph in aetiology, caesium, oenology, oestrogen, etc. (etiology etc. are US usage).\" However, it notes some exceptions like \"medieval and fetus\" which are now normally spelled without the digraph in British English. (Section 3.6)\n",
      "\n",
      "The guide does not provide any other explicit information about differences between US and UK spellings to be used in EU documents.\n",
      "\n",
      "--- Hallucination Evaluation ---\n",
      "{\n",
      "  \"analysis\": [\n",
      "    {\n",
      "      \"sentence\": \"According to the provided sections from the European Commission's English Style Guide:\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is a factual statement introducing the subsequent points from the style guide.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"1. The guide states to \\\"Use the -is- spelling\\\" for words like \\\"organis-e\\\" rather than the \\\"-iz-\\\" spelling like \\\"organiz-e\\\". It says \\\"Both spellings are correct, but this rule is to be followed for the sake of consistency in EU texts.\\\" (Section 3.2)\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is directly supported by Section 3.2 of the source context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"2. For other spelling differences between US and UK English, it instructs to \\\"Follow standard Irish/British usage\\\" and use a spellchecker set to UK English. It recommends following \\\"the first spelling given on the Oxford Dictionaries Premium website\\\" for British English spellings. (Section 3.1)\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is directly supported by Section 3.1 of the source context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"3. Regarding digraphs like \\\"ae\\\" and \\\"oe\\\", it states to \\\"Keep the digraph in aetiology, caesium, oenology, oestrogen, etc. (etiology etc. are US usage).\\\" However, it notes some exceptions like \\\"medieval and fetus\\\" which are now normally spelled without the digraph in British English. (Section 3.6)\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This is directly supported by Section 3.6 of the source context.\"\n",
      "    },\n",
      "    {\n",
      "      \"sentence\": \"The guide does not provide any other explicit information about differences between US and UK spellings to be used in EU documents.\",\n",
      "      \"is_supported\": true,\n",
      "      \"reasoning\": \"This statement accurately claims that no other information about US vs UK spelling differences is present in the provided context.\"\n",
      "    }\n",
      "  ],\n",
      "  \"final_verdict\": \"SUPPORTED\"\n",
      "}\n",
      "\n",
      "\n",
      "--- All experiments complete! ---\n"
     ]
    }
   ],
   "source": [
    "# === RUN EXPERIMENT LOOP ===\n",
    "print(f'--- Running experiments on {len(test_questions)} questions ---')\n",
    "\n",
    "for i, question in enumerate(test_questions):\n",
    "    print(f'\\n====================== QUESTION {i+1}/{len(test_questions)} ======================')\n",
    "    print(f'QUESTION: {question}')\n",
    "    print(f'----------------------------------------------------------\\n')\n",
    "    \n",
    "    # Test with Basic Prompt (Default Temperature)\n",
    "    print('--- 1. ANALYSIS OF BASIC PROMPT (Default Temperature) ---')\n",
    "    basic_response = get_rag_response(question, BASIC_PROMPT_TEMPLATE)\n",
    "    print(f\"GENERATED ANSWER:\\n{basic_response['answer']}\\n\")\n",
    "    \n",
    "    basic_evaluation = evaluate_for_hallucination(basic_response['context'], basic_response['answer'])\n",
    "    print('--- Hallucination Evaluation ---')\n",
    "    print(json.dumps(basic_evaluation, indent=2))\n",
    "    \n",
    "    results_log.append({\n",
    "        'question': question, 'prompt_type': 'basic',\n",
    "        'response': basic_response, 'evaluation': basic_evaluation\n",
    "    })\n",
    "    \n",
    "    print('\\n' + '-'*60 + '\\n')\n",
    "    \n",
    "    # Test with Engineered Prompt (Temperature = 0.0)\n",
    "    print('--- 2. ANALYSIS OF ENGINEERED PROMPT (Temperature = 0.0) ---')\n",
    "    engineered_response = get_rag_response(question, ENGINEERED_PROMPT_TEMPLATE, temperature=0.0) \n",
    "    print(f\"GENERATED ANSWER:\\n{engineered_response['answer']}\\n\")\n",
    "    \n",
    "    engineered_evaluation = evaluate_for_hallucination(engineered_response['context'], engineered_response['answer'])\n",
    "    print('--- Hallucination Evaluation ---')\n",
    "    print(json.dumps(engineered_evaluation, indent=2))\n",
    "    \n",
    "    results_log.append({\n",
    "        'question': question, 'prompt_type': 'engineered',\n",
    "        'response': engineered_response, 'evaluation': engineered_evaluation\n",
    "    })\n",
    "    \n",
    "    # Pause to respect API rate limits\n",
    "    if (i + 1) < len(test_questions):\n",
    "        print('\\nPausing for 5 seconds to avoid rate limiting...')\n",
    "        time.sleep(5)\n",
    "\n",
    "print('\\n\\n--- All experiments complete! ---')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d982e6-6c27-426b-9f3c-036ec5b7a5b7",
   "metadata": {},
   "source": [
    "The detailed output above provides a qualitative view of how each prompt performed. We can see specific examples, like in **Question 7** (comparing EU rules to the Chicago Manual of Style), where the **engineered prompt correctly refused** to answer because the information wasn't in the context, while the **basic prompt attempted to synthesize** an answer before admitting the comparison wasn't present. Similar refusals by the engineered prompt occurred for **Question 6** (EU font face) and **Question 8** (Comic Sans).\n",
    "\n",
    "To get a clear, quantitative comparison, the next cell processes the `results_log` using our `calculate_hallucination_metrics` function. It calculates the overall accuracy and hallucination rates for each prompt type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3952b1e1-ddab-4953-8038-2117fefca8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Quantitative Hallucination Analysis ---\n",
      "================================================================================\n",
      "Metric                              | Basic Prompt         | Engineered Prompt\n",
      "--------------------------------------------------------------------------------\n",
      "Accuracy Rate (Fully Supported)     | 90.00%               | 100.00%             \n",
      "Partial Hallucination Rate          | 10.00%               | 0.00%               \n",
      "Complete Hallucination Rate         | 0.00%                | 0.00%               \n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# === CALCULATE AND DISPLAY FINAL METRICS ===\n",
    "basic_results = [r['evaluation'] for r in results_log if r['prompt_type'] == 'basic']\n",
    "engineered_results = [r['evaluation'] for r in results_log if r['prompt_type'] == 'engineered']\n",
    "\n",
    "basic_metrics = calculate_hallucination_metrics(basic_results)\n",
    "engineered_metrics = calculate_hallucination_metrics(engineered_results)\n",
    "\n",
    "print('--- Quantitative Hallucination Analysis ---')\n",
    "print('='*80)\n",
    "print(f\"{'Metric':<35} | {'Basic Prompt':<20} | {'Engineered Prompt'}\")\n",
    "print('-' * 80)\n",
    "print(f\"{'Accuracy Rate (Fully Supported)':<35} | {basic_metrics.get('accuracy_rate', 0):<20.2%} | {engineered_metrics.get('accuracy_rate', 0):<20.2%}\")\n",
    "print(f\"{'Partial Hallucination Rate':<35} | {basic_metrics.get('partial_hallucination_rate', 0):<20.2%} | {engineered_metrics.get('partial_hallucination_rate', 0):<20.2%}\")\n",
    "print(f\"{'Complete Hallucination Rate':<35} | {basic_metrics.get('hallucination_rate', 0):<20.2%} | {engineered_metrics.get('hallucination_rate', 0):<20.2%}\")\n",
    "print('='*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1425478d-e50f-46b5-8041-c586c9dc5a07",
   "metadata": {},
   "source": [
    "The quantitative results confirm the effectiveness of prompt engineering. The **engineered prompt achieved a 100% accuracy rate**, meaning every answer was fully supported by the retrieved context. The **basic prompt**, while still performing well (90% accuracy), showed a **10% rate of partial hallucination**.\n",
    "\n",
    "This single instance of partial hallucination occurred in **Question 7**, where the basic prompt inferred a comparison to the \"Chicago Manual of Style\" that was not present in the source context. The engineered prompt correctly identified that this comparison was outside the scope of the provided material and declined to answer. This case perfectly illustrates how the engineered prompt's guidelines prevent the model from generating unsupported inferences.\n",
    "\n",
    "This demonstrates that providing **specific, strict guidelines** significantly improves the reliability and trustworthiness of the RAG system's output. Within the scope of this evaluation, the engineered prompt effectively eliminated the partial hallucinations observed with the basic prompt. \n",
    "\n",
    "As the final step in this notebook, the cell below **saves the experimental results**, including the detailed logs for each question, into a timestamped JSON file. It also closes the connection to the Weaviate client to release resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "298a8308-c895-4d2c-b85b-b2f799c40b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Full experiment log saved to: ../results/rag_evaluation_results.json\n",
      "✅ Weaviate client connection closed.\n"
     ]
    }
   ],
   "source": [
    "# === LOG RESULTS AND CLOSE CONNECTION ===\n",
    "\n",
    "# Compile the full log with a timestamp and metadata.\n",
    "full_log = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'model_id': CLAUDE_MODEL_ID,\n",
    "    'retriever_settings': {'alpha': 0.7, 'limit': 5},\n",
    "    'results': results_log\n",
    "}\n",
    "\n",
    "# Ensure the results directory exists and write the log file.\n",
    "os.makedirs('../results', exist_ok=True)\n",
    "with open(RESULTS_FILE_PATH, 'w', encoding='utf-8') as f:\n",
    "    json.dump(full_log, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f'✅ Full experiment log saved to: {RESULTS_FILE_PATH}')\n",
    "\n",
    "# Close the Weaviate client connection to release resources.\n",
    "client_weaviate.close()\n",
    "print('✅ Weaviate client connection closed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f814b44d-324c-4854-b9a7-c15eafd7f584",
   "metadata": {},
   "source": [
    "## **8. Conclusion and Next Steps**\n",
    "\n",
    "This notebook demonstrated that **prompt engineering has a measurable effect on RAG system performance:** The engineered prompt achieved 100% accuracy on the test set, ensuring all answers were fully grounded in the retrieved context. In contrast, the baseline prompt showed a 10% rate of partial hallucination, highlighting the importance of clear, strict instructions for LLM guidance.\n",
    "\n",
    "It's important to acknowledge that **a production-level system would require more extensive validation**. This typically involves a larger test suite, human review or multiple LLM judges, and repeated runs to ensure statistical robustness, even when using low temperature settings for consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5043872-ed3f-49a1-a0e0-d97b4666208b",
   "metadata": {},
   "source": [
    "### **8.1. Deployed Application** \n",
    "\n",
    "Based on these findings, and the optimal chunking (`section-based`) and retrieval (`hybrid search, alpha=0.7`) strategies identified earlier, I developed a **Streamlit web application**. This app provides a chat interface for querying the EU Style Guide, utilizing Weaviate for retrieval and Amazon Bedrock (Claude 3 Sonnet) for generation with the optimized RAG pipeline. The application was containerized with **Docker** and deployed on **Amazon EC2**. \n",
    "\n",
    "The live deployment has been discontinued to manage costs, but a demonstration is available here: [**YouTube App Demo Video**](https://youtu.be/WarXeIrMPQI)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec674ee-c487-4af0-b929-dcb9e2c4aaa0",
   "metadata": {},
   "source": [
    "### **8.2. Future Work**\n",
    "\n",
    "While this project successfully built a complete RAG pipeline, the system can be scaled and enhanced with additional features. Here are some key areas for future development:\n",
    "\n",
    "  * **Expand the Knowledge Base:** Having successfully processed a complex PDF like the EU Style Guide, the pipeline is proven capable and can be readily expanded. It's straightforward to incorporate other useful resources for translators, such as internal **brand guidelines**, structured **terminology or regulatory databases**, or **Translation Memories (TMs)** to ensure consistency.\n",
    "\n",
    "  * **Implement Advanced Retrieval Strategies:** The current hybrid search is effective, but retrieval accuracy can be pushed even further with more sophisticated techniques.\n",
    "\n",
    "      * **Query Transformation:** Implementing a preliminary step to rewrite and expand user queries offers benefits. **Query rewriting** could fix typos, simplify complex phrasing, or rephrase questions for clarity. **Query expansion** could generate multiple variations of a question by adding synonyms or different phrasings, then run retrieval on all of them to maximize the chance of finding the most relevant context.\n",
    "      * **Advanced Filtering and Ranking:** Result selection can also be improved. **Recursive retrieval** could fetch information at multiple levels, starting with high-level summaries and then drilling down into more specific paragraphs. After the initial retrieval, a **re-ranker** (a more powerful but slower model) could be used to re-score the top results, filtering out less relevant documents to ensure only the highest-quality context is passed to the LLM.<br><br>\n",
    "\n",
    "  * **Optimize the LLM Context:** To improve efficiency and focus, implementing **context compression** is an option. This involves using techniques to remove redundant or irrelevant sentences from the retrieved chunks *before* they are sent to the LLM. This makes the context shorter and denser, which can improve response quality and reduce processing costs.\n",
    "\n",
    "  * **Operationalize and Measure Performance:** Moving this from a proof-of-concept to a real-world tool requires operationalization. This includes implementing **optimization strategies** like caching for frequent queries and their embedding results to reduce latency and save costs. More importantly, building a **monitoring dashboard** is necessary to track not just technical performance, but key **business metrics**. This means measuring user satisfaction through ratings (e.g., setting a target of \\>4.0/5.0), tracking task completion rates (did the user find their answer?), and monitoring engagement through follow-up questions to build a system that continuously learns and improves.\n",
    "\n",
    "Overall, this project was a fantastic opportunity to put RAG concepts into practice, from data processing to evaluation and deployment. My next project will focus on exploring **Graph RAG**, so stay tuned\\!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
